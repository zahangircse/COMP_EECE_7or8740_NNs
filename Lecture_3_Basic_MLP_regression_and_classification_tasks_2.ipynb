{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Description\n",
    "- Boston housing dataset has total 506 data instances (404 training & 102 test)\n",
    "- 13 attributes (features) to predict \"the median values of the houses at a location\"\n",
    "- Doc: https://keras.io/datasets/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(404, 13)\n",
      "(404, 13)\n",
      "[[1.73343179e-03 0.00000000e+00 1.14486639e-02 0.00000000e+00\n",
      "  7.56680731e-04 8.63853727e-03 1.28973277e-01 5.59338959e-03\n",
      "  5.62587904e-03 4.31786217e-01 2.95358650e-02 5.58227848e-01\n",
      "  2.63291139e-02]\n",
      " [3.06188467e-05 1.16033755e-01 2.85513361e-03 0.00000000e+00\n",
      "  5.83684951e-04 1.07032349e-02 2.20815752e-02 8.81856540e-03\n",
      "  2.81293952e-03 4.89451477e-01 2.06751055e-02 5.56090014e-01\n",
      "  4.37412096e-03]]\n",
      "(102, 13)\n",
      "(404,)\n",
      "(102,)\n",
      "Y_test values:\n",
      "[ 7.2 18.8 19.  27.  22.2 24.5 31.2 22.9 20.5 23.2 18.6 14.5 17.8 50.\n",
      " 20.8 24.3 24.2 19.8 19.1 22.7 12.  10.2 20.  18.5 20.9 23.  27.5 30.1\n",
      "  9.5 22.  21.2 14.1 33.1 23.4 20.1  7.4 15.4 23.8 20.1 24.5 33.  28.4\n",
      " 14.1 46.7 32.5 29.6 28.4 19.8 20.2 25.  35.4 20.3  9.7 14.5 34.9 26.6\n",
      "  7.2 50.  32.4 21.6 29.8 13.1 27.5 21.2 23.1 21.9 13.  23.2  8.1  5.6\n",
      " 21.7 29.6 19.6  7.  26.4 18.9 20.9 28.1 35.4 10.2 24.3 43.1 17.6 15.4\n",
      " 16.2 27.1 21.4 21.5 22.4 25.  16.6 18.6 22.  42.8 35.1 21.5 36.  21.9\n",
      " 24.1 50.  26.7 25. ]\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_train.shape)\n",
    "print(X_train[:2,:])\n",
    "\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n",
    "print(\"Y_test values:\")\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Creating a models\n",
    "- Keras model object can be created with Sequential class\n",
    "- At the outset, the model is empty per se. It is completed by **'adding'** additional layers and compilation\n",
    "- Doc: https://keras.io/models/sequential/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 10)                140       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 371\n",
      "Trainable params: 371\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Dense\n",
    "model = Sequential()\n",
    "\n",
    "# Keras model with two hidden layer with 10 neurons each \n",
    "model.add(Dense(10, input_shape = (13,)))    # Input layer => input_shape should be explicitly designated\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(Dense(10))                         # Hidden layer => only output dimension should be designated\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(Dense(10))                         # Hidden layer => only output dimension should be designated\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(Dense(1))                          # Output layer => output dimension = 1 since it is regression problem\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 10)                140       \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 371\n",
      "Trainable params: 371\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# This is equivalent to the above code block\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Dense\n",
    "\n",
    "model = Sequential()\n",
    "model2 = Sequential()\n",
    "model2.add(Dense(10, input_shape = (13,), activation = 'sigmoid'))\n",
    "model2.add(Dense(10, activation = 'sigmoid'))\n",
    "model2.add(Dense(10, activation = 'sigmoid'))\n",
    "model2.add(Dense(1))\n",
    "\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-2. Model compile\n",
    "- Keras model should be \"compiled\" prior to training\n",
    "- Types of loss (function) and optimizer should be designated\n",
    "    - Doc (optimizers): https://keras.io/optimizers/\n",
    "    - Doc (losses): https://keras.io/losses/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import optimizers\n",
    "sgd = optimizers.SGD(lr = 0.01)    # stochastic gradient descent optimizer\n",
    "model.compile(optimizer = sgd, loss = 'mean_squared_error', metrics = ['mse'])    # for regression problems, mean squared error (MSE) is often employed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Training\n",
    "- Training the model with training data provided"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup the parameters:\n",
    "- Batch size: 10\n",
    "- Number of Epochs: 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "41/41 [==============================] - 0s 529us/step - loss: 581.9316 - mse: 581.9316\n",
      "Epoch 2/500\n",
      "41/41 [==============================] - 0s 459us/step - loss: 581.9316 - mse: 581.9316\n",
      "Epoch 3/500\n",
      "41/41 [==============================] - 0s 453us/step - loss: 581.9316 - mse: 581.9316\n",
      "Epoch 4/500\n",
      "41/41 [==============================] - 0s 473us/step - loss: 581.9315 - mse: 581.9315\n",
      "Epoch 5/500\n",
      "41/41 [==============================] - 0s 473us/step - loss: 581.9318 - mse: 581.9318\n",
      "Epoch 6/500\n",
      "41/41 [==============================] - 0s 467us/step - loss: 581.9318 - mse: 581.9318\n",
      "Epoch 7/500\n",
      "41/41 [==============================] - 0s 459us/step - loss: 581.9318 - mse: 581.9318\n",
      "Epoch 8/500\n",
      "41/41 [==============================] - 0s 475us/step - loss: 581.9316 - mse: 581.9316\n",
      "Epoch 9/500\n",
      "41/41 [==============================] - 0s 472us/step - loss: 581.9317 - mse: 581.9317\n",
      "Epoch 10/500\n",
      "41/41 [==============================] - 0s 472us/step - loss: 581.9317 - mse: 581.9317\n",
      "Epoch 11/500\n",
      "41/41 [==============================] - 0s 473us/step - loss: 581.9317 - mse: 581.9317\n",
      "Epoch 12/500\n",
      "41/41 [==============================] - 0s 509us/step - loss: 581.9317 - mse: 581.9317\n",
      "Epoch 13/500\n",
      "41/41 [==============================] - 0s 499us/step - loss: 581.9318 - mse: 581.9318\n",
      "Epoch 14/500\n",
      "41/41 [==============================] - 0s 483us/step - loss: 581.9318 - mse: 581.9318\n",
      "Epoch 15/500\n",
      "41/41 [==============================] - 0s 452us/step - loss: 581.9316 - mse: 581.9316\n",
      "Epoch 16/500\n",
      "41/41 [==============================] - 0s 495us/step - loss: 581.9317 - mse: 581.9317\n",
      "Epoch 17/500\n",
      "41/41 [==============================] - 0s 476us/step - loss: 581.9317 - mse: 581.9317\n",
      "Epoch 18/500\n",
      "41/41 [==============================] - 0s 453us/step - loss: 581.9316 - mse: 581.9316\n",
      "Epoch 19/500\n",
      "41/41 [==============================] - 0s 553us/step - loss: 581.9317 - mse: 581.9317\n",
      "Epoch 20/500\n",
      "41/41 [==============================] - 0s 482us/step - loss: 581.9317 - mse: 581.9317\n",
      "Epoch 21/500\n",
      "41/41 [==============================] - 0s 469us/step - loss: 581.9317 - mse: 581.9317\n",
      "Epoch 22/500\n",
      "41/41 [==============================] - 0s 429us/step - loss: 581.9317 - mse: 581.9317\n",
      "Epoch 23/500\n",
      "41/41 [==============================] - 0s 481us/step - loss: 581.9317 - mse: 581.9317\n",
      "Epoch 24/500\n",
      "41/41 [==============================] - 0s 493us/step - loss: 581.9317 - mse: 581.9317\n",
      "Epoch 25/500\n",
      "41/41 [==============================] - 0s 471us/step - loss: 581.9317 - mse: 581.9317\n",
      "Epoch 26/500\n",
      "41/41 [==============================] - 0s 428us/step - loss: 581.9317 - mse: 581.9317\n",
      "Epoch 27/500\n",
      "41/41 [==============================] - 0s 522us/step - loss: 581.9318 - mse: 581.9318\n",
      "Epoch 28/500\n",
      "41/41 [==============================] - 0s 482us/step - loss: 581.9316 - mse: 581.9316\n",
      "Epoch 29/500\n",
      "41/41 [==============================] - 0s 491us/step - loss: 581.9316 - mse: 581.9316\n",
      "Epoch 30/500\n",
      "41/41 [==============================] - 0s 413us/step - loss: 581.9316 - mse: 581.9316\n",
      "Epoch 31/500\n",
      "41/41 [==============================] - 0s 506us/step - loss: 581.9318 - mse: 581.9318\n",
      "Epoch 32/500\n",
      "41/41 [==============================] - 0s 484us/step - loss: 581.9316 - mse: 581.9316\n",
      "Epoch 33/500\n",
      "41/41 [==============================] - 0s 497us/step - loss: 581.9315 - mse: 581.9316\n",
      "Epoch 34/500\n",
      "41/41 [==============================] - 0s 416us/step - loss: 581.9316 - mse: 581.9316\n",
      "Epoch 35/500\n",
      "41/41 [==============================] - 0s 509us/step - loss: 581.9318 - mse: 581.9318\n",
      "Epoch 36/500\n",
      "41/41 [==============================] - 0s 473us/step - loss: 581.9317 - mse: 581.9317\n",
      "Epoch 37/500\n",
      "41/41 [==============================] - 0s 594us/step - loss: 581.9317 - mse: 581.9317\n",
      "Epoch 38/500\n",
      "41/41 [==============================] - 0s 539us/step - loss: 581.9317 - mse: 581.9317\n",
      "Epoch 39/500\n",
      "41/41 [==============================] - 0s 527us/step - loss: 581.9316 - mse: 581.9316\n",
      "Epoch 40/500\n",
      "41/41 [==============================] - 0s 490us/step - loss: 581.9318 - mse: 581.9318\n",
      "Epoch 41/500\n",
      "41/41 [==============================] - 0s 468us/step - loss: 581.9316 - mse: 581.9316\n",
      "Epoch 42/500\n",
      "41/41 [==============================] - 0s 502us/step - loss: 581.9318 - mse: 581.9318\n",
      "Epoch 43/500\n",
      "41/41 [==============================] - 0s 452us/step - loss: 581.9318 - mse: 581.9318\n",
      "Epoch 44/500\n",
      "41/41 [==============================] - 0s 521us/step - loss: 581.9318 - mse: 581.9318\n",
      "Epoch 45/500\n",
      "41/41 [==============================] - 0s 478us/step - loss: 581.9316 - mse: 581.9316\n",
      "Epoch 46/500\n",
      "41/41 [==============================] - 0s 483us/step - loss: 581.9317 - mse: 581.9317\n",
      "Epoch 47/500\n",
      "41/41 [==============================] - 0s 426us/step - loss: 581.9316 - mse: 581.9316\n",
      "Epoch 48/500\n",
      "41/41 [==============================] - 0s 487us/step - loss: 581.9316 - mse: 581.9316\n",
      "Epoch 49/500\n",
      "41/41 [==============================] - 0s 489us/step - loss: 581.9317 - mse: 581.9317\n",
      "Epoch 50/500\n",
      "41/41 [==============================] - 0s 483us/step - loss: 581.9318 - mse: 581.9318\n",
      "Epoch 51/500\n",
      "41/41 [==============================] - 0s 443us/step - loss: 581.9316 - mse: 581.9316\n",
      "Epoch 52/500\n",
      "41/41 [==============================] - 0s 476us/step - loss: 581.9318 - mse: 581.9318\n",
      "Epoch 53/500\n",
      "41/41 [==============================] - 0s 497us/step - loss: 581.9316 - mse: 581.9316\n",
      "Epoch 54/500\n",
      "41/41 [==============================] - 0s 471us/step - loss: 581.9316 - mse: 581.9316\n",
      "Epoch 55/500\n",
      "41/41 [==============================] - 0s 476us/step - loss: 581.9317 - mse: 581.9317\n",
      "Epoch 56/500\n",
      "41/41 [==============================] - 0s 546us/step - loss: 581.9316 - mse: 581.9316\n",
      "Epoch 57/500\n",
      "41/41 [==============================] - 0s 477us/step - loss: 581.9316 - mse: 581.9316\n",
      "Epoch 58/500\n",
      "41/41 [==============================] - 0s 487us/step - loss: 581.9317 - mse: 581.9317\n",
      "Epoch 59/500\n",
      "41/41 [==============================] - 0s 524us/step - loss: 581.9317 - mse: 581.9316\n",
      "Epoch 60/500\n",
      "41/41 [==============================] - 0s 506us/step - loss: 581.9318 - mse: 581.9318\n",
      "Epoch 61/500\n",
      "41/41 [==============================] - 0s 486us/step - loss: 581.9316 - mse: 581.9316\n",
      "Epoch 62/500\n",
      "41/41 [==============================] - 0s 534us/step - loss: 581.9316 - mse: 581.9316\n",
      "Epoch 63/500\n",
      "41/41 [==============================] - 0s 471us/step - loss: 581.9317 - mse: 581.9317\n",
      "Epoch 64/500\n",
      "41/41 [==============================] - 0s 477us/step - loss: 581.9318 - mse: 581.9318\n",
      "Epoch 65/500\n",
      "41/41 [==============================] - 0s 479us/step - loss: 581.9318 - mse: 581.9318\n",
      "Epoch 66/500\n",
      "41/41 [==============================] - 0s 444us/step - loss: 581.9318 - mse: 581.9318\n",
      "Epoch 67/500\n",
      "41/41 [==============================] - 0s 454us/step - loss: 581.9317 - mse: 581.9317\n",
      "Epoch 68/500\n",
      "41/41 [==============================] - 0s 443us/step - loss: 581.9316 - mse: 581.9316\n",
      "Epoch 69/500\n",
      "41/41 [==============================] - 0s 442us/step - loss: 581.9316 - mse: 581.9316\n",
      "Epoch 70/500\n",
      "41/41 [==============================] - 0s 420us/step - loss: 581.9316 - mse: 581.9316\n",
      "Epoch 71/500\n",
      "41/41 [==============================] - 0s 460us/step - loss: 581.9317 - mse: 581.9317\n",
      "Epoch 72/500\n",
      "41/41 [==============================] - 0s 444us/step - loss: 581.9317 - mse: 581.9317\n",
      "Epoch 73/500\n",
      "41/41 [==============================] - 0s 464us/step - loss: 581.9316 - mse: 581.9316\n",
      "Epoch 74/500\n",
      "41/41 [==============================] - 0s 464us/step - loss: 581.9316 - mse: 581.9316\n",
      "Epoch 75/500\n",
      "41/41 [==============================] - 0s 447us/step - loss: 581.9318 - mse: 581.9318\n",
      "Epoch 76/500\n",
      "41/41 [==============================] - 0s 466us/step - loss: 581.9318 - mse: 581.9318\n",
      "Epoch 77/500\n",
      "41/41 [==============================] - 0s 446us/step - loss: 581.9316 - mse: 581.9316\n",
      "Epoch 78/500\n",
      "41/41 [==============================] - 0s 446us/step - loss: 581.9316 - mse: 581.9316\n",
      "Epoch 79/500\n",
      "41/41 [==============================] - 0s 454us/step - loss: 581.9317 - mse: 581.9317\n",
      "Epoch 80/500\n",
      "41/41 [==============================] - 0s 457us/step - loss: 581.9317 - mse: 581.9317\n",
      "Epoch 81/500\n",
      "41/41 [==============================] - 0s 472us/step - loss: 581.9316 - mse: 581.9316\n",
      "Epoch 82/500\n",
      "41/41 [==============================] - 0s 451us/step - loss: 581.9318 - mse: 581.9318\n",
      "Epoch 83/500\n",
      "41/41 [==============================] - 0s 456us/step - loss: 581.9318 - mse: 581.9318\n",
      "Epoch 84/500\n",
      "41/41 [==============================] - 0s 457us/step - loss: 581.9317 - mse: 581.9317\n",
      "Epoch 85/500\n",
      "41/41 [==============================] - 0s 463us/step - loss: 581.9318 - mse: 581.9318\n",
      "Epoch 86/500\n",
      "41/41 [==============================] - 0s 478us/step - loss: 581.9316 - mse: 581.9316\n",
      "Epoch 87/500\n",
      "41/41 [==============================] - 0s 443us/step - loss: 581.9316 - mse: 581.9316\n",
      "Epoch 88/500\n",
      "41/41 [==============================] - 0s 437us/step - loss: 581.9318 - mse: 581.9318\n",
      "Epoch 89/500\n",
      "41/41 [==============================] - 0s 444us/step - loss: 581.9318 - mse: 581.9318\n",
      "Epoch 90/500\n",
      "41/41 [==============================] - 0s 431us/step - loss: 581.9316 - mse: 581.9316\n",
      "Epoch 91/500\n",
      "41/41 [==============================] - 0s 414us/step - loss: 581.9316 - mse: 581.9316\n",
      "Epoch 92/500\n",
      "41/41 [==============================] - 0s 425us/step - loss: 581.9318 - mse: 581.9318\n",
      "Epoch 93/500\n",
      "41/41 [==============================] - 0s 436us/step - loss: 581.9316 - mse: 581.9316\n",
      "Epoch 94/500\n",
      "41/41 [==============================] - 0s 433us/step - loss: 581.9317 - mse: 581.9317\n",
      "Epoch 95/500\n",
      "41/41 [==============================] - 0s 438us/step - loss: 581.9317 - mse: 581.9317\n",
      "Epoch 96/500\n",
      "41/41 [==============================] - 0s 459us/step - loss: 581.9316 - mse: 581.9316\n",
      "Epoch 97/500\n",
      "41/41 [==============================] - 0s 423us/step - loss: 581.9318 - mse: 581.9318\n",
      "Epoch 98/500\n",
      "41/41 [==============================] - 0s 424us/step - loss: 581.9316 - mse: 581.9316\n",
      "Epoch 99/500\n",
      "41/41 [==============================] - 0s 462us/step - loss: 581.9318 - mse: 581.9318\n",
      "Epoch 100/500\n",
      "41/41 [==============================] - 0s 446us/step - loss: 581.9318 - mse: 581.9318\n",
      "Epoch 101/500\n",
      "41/41 [==============================] - 0s 445us/step - loss: 581.9317 - mse: 581.9317\n",
      "Epoch 102/500\n",
      "41/41 [==============================] - 0s 454us/step - loss: 581.9318 - mse: 581.9318\n",
      "Epoch 103/500\n",
      "41/41 [==============================] - 0s 450us/step - loss: 581.9316 - mse: 581.9316\n",
      "Epoch 104/500\n",
      "41/41 [==============================] - 0s 493us/step - loss: 581.9316 - mse: 581.9316\n",
      "Epoch 105/500\n",
      "41/41 [==============================] - 0s 479us/step - loss: 581.9316 - mse: 581.9316\n",
      "Epoch 106/500\n",
      "41/41 [==============================] - 0s 458us/step - loss: 581.9318 - mse: 581.9318\n",
      "Epoch 107/500\n",
      "41/41 [==============================] - 0s 468us/step - loss: 581.9316 - mse: 581.9316\n",
      "Epoch 108/500\n",
      "41/41 [==============================] - 0s 460us/step - loss: 581.9318 - mse: 581.9318\n",
      "Epoch 109/500\n",
      "41/41 [==============================] - 0s 444us/step - loss: 581.9316 - mse: 581.9316\n",
      "Epoch 110/500\n",
      "41/41 [==============================] - 0s 450us/step - loss: 581.9317 - mse: 581.9317\n",
      "Epoch 111/500\n",
      "41/41 [==============================] - 0s 516us/step - loss: 581.9318 - mse: 581.9318\n",
      "Epoch 112/500\n",
      "41/41 [==============================] - 0s 453us/step - loss: 581.9316 - mse: 581.9316\n",
      "Epoch 113/500\n",
      "41/41 [==============================] - 0s 443us/step - loss: 581.9316 - mse: 581.9316\n",
      "Epoch 114/500\n",
      "41/41 [==============================] - 0s 470us/step - loss: 581.9318 - mse: 581.9318\n",
      "Epoch 115/500\n",
      "41/41 [==============================] - 0s 443us/step - loss: 581.9318 - mse: 581.9316\n",
      "Epoch 116/500\n",
      "41/41 [==============================] - 0s 454us/step - loss: 581.9316 - mse: 581.9316\n",
      "Epoch 117/500\n",
      "41/41 [==============================] - 0s 433us/step - loss: 581.9316 - mse: 581.9316\n",
      "Epoch 118/500\n",
      "41/41 [==============================] - 0s 465us/step - loss: 581.9316 - mse: 581.9316\n",
      "Epoch 119/500\n",
      "41/41 [==============================] - 0s 419us/step - loss: 581.9318 - mse: 581.9318\n",
      "Epoch 120/500\n",
      "41/41 [==============================] - 0s 430us/step - loss: 581.9316 - mse: 581.9316\n",
      "Epoch 121/500\n",
      "41/41 [==============================] - 0s 455us/step - loss: 581.9317 - mse: 581.9317\n",
      "Epoch 122/500\n",
      "41/41 [==============================] - 0s 438us/step - loss: 581.9317 - mse: 581.9317\n",
      "Epoch 123/500\n",
      "41/41 [==============================] - 0s 445us/step - loss: 581.9316 - mse: 581.9316\n",
      "Epoch 124/500\n",
      "41/41 [==============================] - 0s 468us/step - loss: 581.9318 - mse: 581.9318\n",
      "Epoch 125/500\n",
      "41/41 [==============================] - 0s 458us/step - loss: 581.9318 - mse: 581.9318\n",
      "Epoch 126/500\n",
      "41/41 [==============================] - 0s 458us/step - loss: 581.9316 - mse: 581.9316\n",
      "Epoch 127/500\n",
      "41/41 [==============================] - 0s 458us/step - loss: 581.9318 - mse: 581.9318\n",
      "Epoch 128/500\n",
      "41/41 [==============================] - 0s 464us/step - loss: 581.9316 - mse: 581.9316\n",
      "Epoch 129/500\n",
      "41/41 [==============================] - 0s 454us/step - loss: 581.9316 - mse: 581.9316\n",
      "Epoch 130/500\n",
      "41/41 [==============================] - 0s 438us/step - loss: 581.9318 - mse: 581.9318\n",
      "Epoch 131/500\n",
      "41/41 [==============================] - 0s 451us/step - loss: 581.9316 - mse: 581.9316\n",
      "Epoch 132/500\n",
      "41/41 [==============================] - 0s 438us/step - loss: 581.9318 - mse: 581.9318\n",
      "Epoch 133/500\n",
      "41/41 [==============================] - 0s 462us/step - loss: 581.9316 - mse: 581.9316\n",
      "Epoch 134/500\n",
      "41/41 [==============================] - 0s 477us/step - loss: 581.9318 - mse: 581.9318\n",
      "Epoch 135/500\n",
      "41/41 [==============================] - 0s 490us/step - loss: 581.9317 - mse: 581.9317\n",
      "Epoch 136/500\n",
      "41/41 [==============================] - 0s 458us/step - loss: 581.9318 - mse: 581.9318\n",
      "Epoch 137/500\n",
      "41/41 [==============================] - 0s 436us/step - loss: 581.9318 - mse: 581.9318\n",
      "Epoch 138/500\n",
      "41/41 [==============================] - 0s 437us/step - loss: 581.9316 - mse: 581.9316\n",
      "Epoch 139/500\n",
      "41/41 [==============================] - 0s 446us/step - loss: 581.9316 - mse: 581.9316\n",
      "Epoch 140/500\n",
      "41/41 [==============================] - 0s 439us/step - loss: 581.9318 - mse: 581.9318\n",
      "Epoch 141/500\n",
      "41/41 [==============================] - 0s 432us/step - loss: 581.9318 - mse: 581.9318\n",
      "Epoch 142/500\n",
      "41/41 [==============================] - 0s 432us/step - loss: 581.9316 - mse: 581.9316\n",
      "Epoch 143/500\n",
      "41/41 [==============================] - 0s 451us/step - loss: 581.9316 - mse: 581.9316\n",
      "Epoch 144/500\n",
      "41/41 [==============================] - 0s 443us/step - loss: 581.9317 - mse: 581.9317\n",
      "Epoch 145/500\n",
      "41/41 [==============================] - 0s 416us/step - loss: 581.9317 - mse: 581.9317\n",
      "Epoch 146/500\n",
      "41/41 [==============================] - 0s 442us/step - loss: 581.9316 - mse: 581.9316\n",
      "Epoch 147/500\n",
      "41/41 [==============================] - 0s 454us/step - loss: 581.9318 - mse: 581.9318\n",
      "Epoch 148/500\n",
      "41/41 [==============================] - 0s 440us/step - loss: 581.9316 - mse: 581.9316\n",
      "Epoch 149/500\n",
      "41/41 [==============================] - 0s 422us/step - loss: 581.9318 - mse: 581.9318\n",
      "Epoch 150/500\n",
      "41/41 [==============================] - 0s 506us/step - loss: 581.9316 - mse: 581.9316\n",
      "Epoch 151/500\n",
      "41/41 [==============================] - 0s 449us/step - loss: 581.9317 - mse: 581.9317\n",
      "Epoch 152/500\n",
      "41/41 [==============================] - 0s 477us/step - loss: 581.9316 - mse: 581.9316\n",
      "Epoch 153/500\n",
      "41/41 [==============================] - 0s 449us/step - loss: 581.9316 - mse: 581.9316\n",
      "Epoch 154/500\n",
      "41/41 [==============================] - 0s 439us/step - loss: 581.9316 - mse: 581.9316\n",
      "Epoch 155/500\n",
      "41/41 [==============================] - 0s 442us/step - loss: 581.9317 - mse: 581.9317\n",
      "Epoch 156/500\n",
      "41/41 [==============================] - 0s 447us/step - loss: 581.9318 - mse: 581.9318\n",
      "Epoch 157/500\n",
      "41/41 [==============================] - 0s 459us/step - loss: 581.9316 - mse: 581.9316\n",
      "Epoch 158/500\n",
      "41/41 [==============================] - 0s 450us/step - loss: 581.9317 - mse: 581.9317\n",
      "Epoch 159/500\n",
      "41/41 [==============================] - 0s 446us/step - loss: 581.9317 - mse: 581.9317\n",
      "Epoch 160/500\n",
      "41/41 [==============================] - 0s 454us/step - loss: 581.9317 - mse: 581.9317\n",
      "Epoch 161/500\n",
      "41/41 [==============================] - 0s 451us/step - loss: 581.9317 - mse: 581.9317\n",
      "Epoch 162/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - 0s 472us/step - loss: 581.9316 - mse: 581.9316\n",
      "Epoch 163/500\n",
      "41/41 [==============================] - 0s 443us/step - loss: 581.9317 - mse: 581.9318\n",
      "Epoch 164/500\n",
      "41/41 [==============================] - 0s 420us/step - loss: 581.9317 - mse: 581.9317\n",
      "Epoch 165/500\n",
      "41/41 [==============================] - 0s 447us/step - loss: 581.9317 - mse: 581.9317\n",
      "Epoch 166/500\n",
      "41/41 [==============================] - 0s 443us/step - loss: 581.9318 - mse: 581.9318\n",
      "Epoch 167/500\n",
      "41/41 [==============================] - 0s 435us/step - loss: 581.9318 - mse: 581.9318\n",
      "Epoch 168/500\n",
      "41/41 [==============================] - 0s 456us/step - loss: 581.9316 - mse: 581.9316\n",
      "Epoch 169/500\n",
      "41/41 [==============================] - 0s 442us/step - loss: 581.9317 - mse: 581.9317\n",
      "Epoch 170/500\n",
      "41/41 [==============================] - 0s 436us/step - loss: 581.9316 - mse: 581.9316\n",
      "Epoch 171/500\n",
      "41/41 [==============================] - 0s 425us/step - loss: 581.9317 - mse: 581.9317\n",
      "Epoch 172/500\n",
      "41/41 [==============================] - 0s 440us/step - loss: 581.9316 - mse: 581.9316\n",
      "Epoch 173/500\n",
      "41/41 [==============================] - 0s 422us/step - loss: 581.9318 - mse: 581.9318\n",
      "Epoch 174/500\n",
      "41/41 [==============================] - 0s 422us/step - loss: 581.9317 - mse: 581.9317\n",
      "Epoch 175/500\n",
      "41/41 [==============================] - 0s 420us/step - loss: 581.9316 - mse: 581.9316\n",
      "Epoch 176/500\n",
      "41/41 [==============================] - 0s 450us/step - loss: 581.9318 - mse: 581.9317\n",
      "Epoch 177/500\n",
      "41/41 [==============================] - 0s 426us/step - loss: 581.9316 - mse: 581.9316\n",
      "Epoch 178/500\n",
      "41/41 [==============================] - 0s 472us/step - loss: 581.9316 - mse: 581.9316\n",
      "Epoch 179/500\n",
      "41/41 [==============================] - 0s 444us/step - loss: 581.9318 - mse: 581.9318\n",
      "Epoch 180/500\n",
      "41/41 [==============================] - 0s 440us/step - loss: 581.9316 - mse: 581.9316\n",
      "Epoch 181/500\n",
      "41/41 [==============================] - 0s 466us/step - loss: 581.9316 - mse: 581.9316\n",
      "Epoch 182/500\n",
      "41/41 [==============================] - 0s 463us/step - loss: 581.9317 - mse: 581.9317\n",
      "Epoch 183/500\n",
      "41/41 [==============================] - 0s 447us/step - loss: 581.9317 - mse: 581.9317\n",
      "Epoch 184/500\n",
      "41/41 [==============================] - 0s 456us/step - loss: 581.9317 - mse: 581.9317\n",
      "Epoch 185/500\n",
      "41/41 [==============================] - 0s 445us/step - loss: 581.9316 - mse: 581.9316\n",
      "Epoch 186/500\n",
      "41/41 [==============================] - 0s 519us/step - loss: 581.9318 - mse: 581.9318\n",
      "Epoch 187/500\n",
      "41/41 [==============================] - 0s 458us/step - loss: 581.9318 - mse: 581.9318\n",
      "Epoch 188/500\n",
      "41/41 [==============================] - 0s 446us/step - loss: 581.9318 - mse: 581.9318\n",
      "Epoch 189/500\n",
      "41/41 [==============================] - 0s 438us/step - loss: 581.9318 - mse: 581.9318\n",
      "Epoch 190/500\n",
      "41/41 [==============================] - 0s 503us/step - loss: 581.9316 - mse: 581.9316\n",
      "Epoch 191/500\n",
      "41/41 [==============================] - 0s 462us/step - loss: 581.9317 - mse: 581.9317\n",
      "Epoch 192/500\n",
      "41/41 [==============================] - 0s 419us/step - loss: 581.9318 - mse: 581.9318\n",
      "Epoch 193/500\n",
      "41/41 [==============================] - 0s 427us/step - loss: 581.9316 - mse: 581.9316\n",
      "Epoch 194/500\n",
      "41/41 [==============================] - 0s 441us/step - loss: 581.9316 - mse: 581.9316\n",
      "Epoch 195/500\n",
      "41/41 [==============================] - 0s 441us/step - loss: 581.9317 - mse: 581.9317\n",
      "Epoch 196/500\n",
      "41/41 [==============================] - 0s 447us/step - loss: 581.9316 - mse: 581.9316\n",
      "Epoch 197/500\n",
      "41/41 [==============================] - 0s 441us/step - loss: 581.9316 - mse: 581.9316\n",
      "Epoch 198/500\n",
      "41/41 [==============================] - 0s 448us/step - loss: 581.9318 - mse: 581.9318\n",
      "Epoch 199/500\n",
      "41/41 [==============================] - 0s 431us/step - loss: 581.9316 - mse: 581.9316\n",
      "Epoch 200/500\n",
      "41/41 [==============================] - 0s 432us/step - loss: 581.9316 - mse: 581.9316\n",
      "Epoch 201/500\n",
      "41/41 [==============================] - 0s 455us/step - loss: 581.9318 - mse: 581.9316\n",
      "Epoch 202/500\n",
      "41/41 [==============================] - 0s 461us/step - loss: 581.9318 - mse: 581.9318\n",
      "Epoch 203/500\n",
      "41/41 [==============================] - 0s 485us/step - loss: 581.9318 - mse: 581.9317\n",
      "Epoch 204/500\n",
      "41/41 [==============================] - 0s 462us/step - loss: 581.9316 - mse: 581.9316\n",
      "Epoch 205/500\n",
      "41/41 [==============================] - 0s 459us/step - loss: 581.9317 - mse: 581.9317\n",
      "Epoch 206/500\n",
      "41/41 [==============================] - 0s 436us/step - loss: 581.9316 - mse: 581.9316\n",
      "Epoch 207/500\n",
      "41/41 [==============================] - 0s 432us/step - loss: 581.9317 - mse: 581.9317\n",
      "Epoch 208/500\n",
      "41/41 [==============================] - 0s 449us/step - loss: 581.9318 - mse: 581.9318\n",
      "Epoch 209/500\n",
      "41/41 [==============================] - 0s 438us/step - loss: 581.9316 - mse: 581.9316\n",
      "Epoch 210/500\n",
      "41/41 [==============================] - 0s 438us/step - loss: 581.9318 - mse: 581.9318\n",
      "Epoch 211/500\n",
      "41/41 [==============================] - 0s 457us/step - loss: 581.9316 - mse: 581.9316\n",
      "Epoch 212/500\n",
      "41/41 [==============================] - 0s 412us/step - loss: 581.9316 - mse: 581.9316\n",
      "Epoch 213/500\n",
      "41/41 [==============================] - 0s 425us/step - loss: 581.9316 - mse: 581.9316\n",
      "Epoch 214/500\n",
      "41/41 [==============================] - 0s 445us/step - loss: 581.9316 - mse: 581.9316\n",
      "Epoch 215/500\n",
      "41/41 [==============================] - 0s 448us/step - loss: 581.9317 - mse: 581.9317\n",
      "Epoch 216/500\n",
      "41/41 [==============================] - 0s 452us/step - loss: 581.9318 - mse: 581.9318\n",
      "Epoch 217/500\n",
      "41/41 [==============================] - 0s 456us/step - loss: 581.9316 - mse: 581.9316\n",
      "Epoch 218/500\n",
      "41/41 [==============================] - 0s 435us/step - loss: 581.9316 - mse: 581.9316\n",
      "Epoch 219/500\n",
      "41/41 [==============================] - 0s 450us/step - loss: 581.9317 - mse: 581.9317\n",
      "Epoch 220/500\n",
      "41/41 [==============================] - 0s 444us/step - loss: 581.9317 - mse: 581.9317\n",
      "Epoch 221/500\n",
      "41/41 [==============================] - 0s 439us/step - loss: 581.9316 - mse: 581.9316\n",
      "Epoch 222/500\n",
      "41/41 [==============================] - 0s 437us/step - loss: 581.9317 - mse: 581.9317\n",
      "Epoch 223/500\n",
      "41/41 [==============================] - 0s 464us/step - loss: 581.9318 - mse: 581.9318\n",
      "Epoch 224/500\n",
      "41/41 [==============================] - 0s 443us/step - loss: 581.9317 - mse: 581.9317\n",
      "Epoch 225/500\n",
      "41/41 [==============================] - 0s 415us/step - loss: 581.9316 - mse: 581.9316\n",
      "Epoch 226/500\n",
      "41/41 [==============================] - 0s 412us/step - loss: 581.9316 - mse: 581.9316\n",
      "Epoch 227/500\n",
      "41/41 [==============================] - 0s 442us/step - loss: 581.9317 - mse: 581.9317\n",
      "Epoch 228/500\n",
      "41/41 [==============================] - 0s 431us/step - loss: 581.9316 - mse: 581.9316\n",
      "Epoch 229/500\n",
      "41/41 [==============================] - 0s 411us/step - loss: 581.9316 - mse: 581.9316\n",
      "Epoch 230/500\n",
      "41/41 [==============================] - 0s 443us/step - loss: 581.9316 - mse: 581.9316\n",
      "Epoch 231/500\n",
      "41/41 [==============================] - 0s 435us/step - loss: 581.9316 - mse: 581.9316\n",
      "Epoch 232/500\n",
      "41/41 [==============================] - 0s 432us/step - loss: 581.9316 - mse: 581.9316\n",
      "Epoch 233/500\n",
      "41/41 [==============================] - 0s 452us/step - loss: 581.9316 - mse: 581.9316\n",
      "Epoch 234/500\n",
      "41/41 [==============================] - 0s 432us/step - loss: 581.9316 - mse: 581.9316\n",
      "Epoch 235/500\n",
      "41/41 [==============================] - 0s 452us/step - loss: 581.9316 - mse: 581.9316\n",
      "Epoch 236/500\n",
      "41/41 [==============================] - 0s 437us/step - loss: 581.9317 - mse: 581.9317\n",
      "Epoch 237/500\n",
      "41/41 [==============================] - 0s 419us/step - loss: 581.9316 - mse: 581.9316\n",
      "Epoch 238/500\n",
      "41/41 [==============================] - 0s 439us/step - loss: 581.9318 - mse: 581.9317\n",
      "Epoch 239/500\n",
      "41/41 [==============================] - 0s 455us/step - loss: 581.9316 - mse: 581.9316\n",
      "Epoch 240/500\n",
      "41/41 [==============================] - 0s 436us/step - loss: 581.9317 - mse: 581.9317\n",
      "Epoch 241/500\n",
      "41/41 [==============================] - 0s 447us/step - loss: 581.9316 - mse: 581.9316\n",
      "Epoch 242/500\n",
      "41/41 [==============================] - 0s 455us/step - loss: 581.9316 - mse: 581.9316\n",
      "Epoch 243/500\n",
      "41/41 [==============================] - 0s 449us/step - loss: 581.9317 - mse: 581.9318\n",
      "Epoch 244/500\n",
      "41/41 [==============================] - 0s 452us/step - loss: 581.9316 - mse: 581.9316\n",
      "Epoch 245/500\n",
      "41/41 [==============================] - 0s 446us/step - loss: 581.9317 - mse: 581.9317\n",
      "Epoch 246/500\n",
      "41/41 [==============================] - 0s 429us/step - loss: 581.9316 - mse: 581.9316\n",
      "Epoch 247/500\n",
      "41/41 [==============================] - 0s 415us/step - loss: 581.9317 - mse: 581.9317\n",
      "Epoch 248/500\n",
      "41/41 [==============================] - 0s 435us/step - loss: 581.9316 - mse: 581.9316\n",
      "Epoch 249/500\n",
      "41/41 [==============================] - 0s 434us/step - loss: 581.9318 - mse: 581.9318\n",
      "Epoch 250/500\n",
      "41/41 [==============================] - 0s 429us/step - loss: 581.9316 - mse: 581.9316\n",
      "Epoch 251/500\n",
      "41/41 [==============================] - 0s 459us/step - loss: 581.9316 - mse: 581.9316\n",
      "Epoch 252/500\n",
      "41/41 [==============================] - 0s 441us/step - loss: 581.9318 - mse: 581.9318\n",
      "Epoch 253/500\n",
      "41/41 [==============================] - 0s 445us/step - loss: 581.9316 - mse: 581.9316\n",
      "Epoch 254/500\n",
      "41/41 [==============================] - 0s 455us/step - loss: 581.9316 - mse: 581.9317\n",
      "Epoch 255/500\n",
      "41/41 [==============================] - 0s 484us/step - loss: 581.9318 - mse: 581.9318\n",
      "Epoch 256/500\n",
      "41/41 [==============================] - 0s 459us/step - loss: 581.9317 - mse: 581.9317\n",
      "Epoch 257/500\n",
      "41/41 [==============================] - 0s 461us/step - loss: 581.9316 - mse: 581.9316\n",
      "Epoch 258/500\n",
      "41/41 [==============================] - 0s 457us/step - loss: 581.9316 - mse: 581.9316\n",
      "Epoch 259/500\n",
      "41/41 [==============================] - 0s 447us/step - loss: 581.9316 - mse: 581.9317\n",
      "Epoch 260/500\n",
      "41/41 [==============================] - 0s 438us/step - loss: 581.9318 - mse: 581.9318\n",
      "Epoch 261/500\n",
      "41/41 [==============================] - 0s 533us/step - loss: 581.9316 - mse: 581.9316\n",
      "Epoch 262/500\n",
      "41/41 [==============================] - 0s 537us/step - loss: 581.9316 - mse: 581.9316\n",
      "Epoch 263/500\n",
      "41/41 [==============================] - 0s 548us/step - loss: 581.9317 - mse: 581.9317\n",
      "Epoch 264/500\n",
      "41/41 [==============================] - 0s 429us/step - loss: 581.9316 - mse: 581.9316\n",
      "Epoch 265/500\n",
      "41/41 [==============================] - 0s 433us/step - loss: 581.9317 - mse: 581.9317\n",
      "Epoch 266/500\n",
      "41/41 [==============================] - 0s 455us/step - loss: 581.9316 - mse: 581.9316\n",
      "Epoch 267/500\n",
      "41/41 [==============================] - 0s 439us/step - loss: 581.9318 - mse: 581.9318\n",
      "Epoch 268/500\n",
      "41/41 [==============================] - 0s 461us/step - loss: 581.9317 - mse: 581.9317\n",
      "Epoch 269/500\n",
      "41/41 [==============================] - 0s 426us/step - loss: 581.9316 - mse: 581.9316\n",
      "Epoch 270/500\n",
      "41/41 [==============================] - 0s 405us/step - loss: 581.9316 - mse: 581.9316\n",
      "Epoch 271/500\n",
      "41/41 [==============================] - 0s 416us/step - loss: 581.9317 - mse: 581.9317\n",
      "Epoch 272/500\n",
      "41/41 [==============================] - 0s 419us/step - loss: 581.9316 - mse: 581.9316\n",
      "Epoch 273/500\n",
      "41/41 [==============================] - 0s 428us/step - loss: 581.9317 - mse: 581.9317\n",
      "Epoch 274/500\n",
      "41/41 [==============================] - 0s 435us/step - loss: 581.9316 - mse: 581.9316\n",
      "Epoch 275/500\n",
      "41/41 [==============================] - 0s 433us/step - loss: 581.9317 - mse: 581.9317\n",
      "Epoch 276/500\n",
      "41/41 [==============================] - 0s 437us/step - loss: 581.9317 - mse: 581.9316\n",
      "Epoch 277/500\n",
      "41/41 [==============================] - 0s 446us/step - loss: 581.9317 - mse: 581.9317\n",
      "Epoch 278/500\n",
      "41/41 [==============================] - 0s 439us/step - loss: 581.9316 - mse: 581.9316\n",
      "Epoch 279/500\n",
      "41/41 [==============================] - 0s 430us/step - loss: 581.9318 - mse: 581.9318\n",
      "Epoch 280/500\n",
      "41/41 [==============================] - 0s 453us/step - loss: 581.9316 - mse: 581.9316\n",
      "Epoch 281/500\n",
      "41/41 [==============================] - 0s 434us/step - loss: 581.9317 - mse: 581.9317\n",
      "Epoch 282/500\n",
      "41/41 [==============================] - 0s 451us/step - loss: 581.9316 - mse: 581.9316\n",
      "Epoch 283/500\n",
      "41/41 [==============================] - 0s 453us/step - loss: 581.9318 - mse: 581.9318\n",
      "Epoch 284/500\n",
      "41/41 [==============================] - 0s 428us/step - loss: 581.9317 - mse: 581.9317\n",
      "Epoch 285/500\n",
      "41/41 [==============================] - 0s 446us/step - loss: 581.9316 - mse: 581.9317\n",
      "Epoch 286/500\n",
      "41/41 [==============================] - 0s 444us/step - loss: 581.9318 - mse: 581.9318\n",
      "Epoch 287/500\n",
      "41/41 [==============================] - 0s 438us/step - loss: 581.9317 - mse: 581.9317\n",
      "Epoch 288/500\n",
      "41/41 [==============================] - 0s 453us/step - loss: 581.9317 - mse: 581.9317\n",
      "Epoch 289/500\n",
      "41/41 [==============================] - 0s 450us/step - loss: 581.9318 - mse: 581.9318\n",
      "Epoch 290/500\n",
      "41/41 [==============================] - 0s 444us/step - loss: 581.9318 - mse: 581.9318\n",
      "Epoch 291/500\n",
      "41/41 [==============================] - 0s 461us/step - loss: 581.9318 - mse: 581.9318\n",
      "Epoch 292/500\n",
      "41/41 [==============================] - 0s 447us/step - loss: 581.9318 - mse: 581.9318\n",
      "Epoch 293/500\n",
      "41/41 [==============================] - 0s 427us/step - loss: 581.9317 - mse: 581.9316\n",
      "Epoch 294/500\n",
      "41/41 [==============================] - 0s 429us/step - loss: 581.9316 - mse: 581.9316\n",
      "Epoch 295/500\n",
      "41/41 [==============================] - 0s 431us/step - loss: 581.9316 - mse: 581.9316\n",
      "Epoch 296/500\n",
      "41/41 [==============================] - 0s 428us/step - loss: 581.9318 - mse: 581.9318\n",
      "Epoch 297/500\n",
      "41/41 [==============================] - 0s 458us/step - loss: 581.9316 - mse: 581.9316\n",
      "Epoch 298/500\n",
      "41/41 [==============================] - 0s 466us/step - loss: 581.9316 - mse: 581.9316\n",
      "Epoch 299/500\n",
      "41/41 [==============================] - 0s 445us/step - loss: 581.9316 - mse: 581.9316\n",
      "Epoch 300/500\n",
      "41/41 [==============================] - 0s 461us/step - loss: 581.9317 - mse: 581.9317\n",
      "Epoch 301/500\n",
      "41/41 [==============================] - 0s 453us/step - loss: 581.9318 - mse: 581.9318\n",
      "Epoch 302/500\n",
      "41/41 [==============================] - 0s 471us/step - loss: 581.9318 - mse: 581.9318\n",
      "Epoch 303/500\n",
      "41/41 [==============================] - 0s 454us/step - loss: 581.9317 - mse: 581.9317\n",
      "Epoch 304/500\n",
      "41/41 [==============================] - 0s 452us/step - loss: 581.9316 - mse: 581.9316\n",
      "Epoch 305/500\n",
      "41/41 [==============================] - 0s 432us/step - loss: 581.9318 - mse: 581.9318\n",
      "Epoch 306/500\n",
      "41/41 [==============================] - 0s 456us/step - loss: 581.9316 - mse: 581.9316\n",
      "Epoch 307/500\n",
      "41/41 [==============================] - 0s 477us/step - loss: 581.9315 - mse: 581.9315\n",
      "Epoch 308/500\n",
      "41/41 [==============================] - 0s 437us/step - loss: 581.9317 - mse: 581.9317\n",
      "Epoch 309/500\n",
      "41/41 [==============================] - 0s 459us/step - loss: 581.9316 - mse: 581.9316\n",
      "Epoch 310/500\n",
      "41/41 [==============================] - 0s 448us/step - loss: 581.9316 - mse: 581.9316\n",
      "Epoch 311/500\n",
      "41/41 [==============================] - 0s 419us/step - loss: 581.9317 - mse: 581.9316\n",
      "Epoch 312/500\n",
      "41/41 [==============================] - 0s 414us/step - loss: 581.9316 - mse: 581.9316\n",
      "Epoch 313/500\n",
      "41/41 [==============================] - 0s 460us/step - loss: 581.9318 - mse: 581.9318\n",
      "Epoch 314/500\n",
      "41/41 [==============================] - 0s 467us/step - loss: 581.9316 - mse: 581.9316\n",
      "Epoch 315/500\n",
      "41/41 [==============================] - 0s 453us/step - loss: 581.9316 - mse: 581.9316\n",
      "Epoch 316/500\n",
      "41/41 [==============================] - 0s 438us/step - loss: 581.9318 - mse: 581.9317\n",
      "Epoch 317/500\n",
      "41/41 [==============================] - 0s 459us/step - loss: 581.9318 - mse: 581.9318\n",
      "Epoch 318/500\n",
      "41/41 [==============================] - 0s 451us/step - loss: 581.9318 - mse: 581.9318\n",
      "Epoch 319/500\n",
      "41/41 [==============================] - 0s 451us/step - loss: 581.9317 - mse: 581.9317\n",
      "Epoch 320/500\n",
      "41/41 [==============================] - 0s 442us/step - loss: 581.9317 - mse: 581.9317\n",
      "Epoch 321/500\n",
      "41/41 [==============================] - 0s 459us/step - loss: 581.9317 - mse: 581.9317\n",
      "Epoch 322/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - 0s 442us/step - loss: 581.9316 - mse: 581.9316\n",
      "Epoch 323/500\n",
      "41/41 [==============================] - 0s 453us/step - loss: 581.9317 - mse: 581.9317\n",
      "Epoch 324/500\n",
      "41/41 [==============================] - 0s 435us/step - loss: 581.9316 - mse: 581.9316\n",
      "Epoch 325/500\n",
      "41/41 [==============================] - 0s 427us/step - loss: 581.9318 - mse: 581.9318\n",
      "Epoch 326/500\n",
      "41/41 [==============================] - 0s 446us/step - loss: 581.9316 - mse: 581.9316\n",
      "Epoch 327/500\n",
      "41/41 [==============================] - 0s 457us/step - loss: 581.9316 - mse: 581.9316\n",
      "Epoch 328/500\n",
      "41/41 [==============================] - 0s 439us/step - loss: 581.9316 - mse: 581.9316\n",
      "Epoch 329/500\n",
      "41/41 [==============================] - 0s 554us/step - loss: 581.9316 - mse: 581.9316\n",
      "Epoch 330/500\n",
      "41/41 [==============================] - 0s 474us/step - loss: 581.9317 - mse: 581.9317\n",
      "Epoch 331/500\n",
      "41/41 [==============================] - 0s 486us/step - loss: 581.9316 - mse: 581.9316\n",
      "Epoch 332/500\n",
      "41/41 [==============================] - 0s 422us/step - loss: 581.9317 - mse: 581.9317\n",
      "Epoch 333/500\n",
      "41/41 [==============================] - 0s 452us/step - loss: 581.9316 - mse: 581.9316\n",
      "Epoch 334/500\n",
      "41/41 [==============================] - 0s 456us/step - loss: 581.9317 - mse: 581.9317\n",
      "Epoch 335/500\n",
      "41/41 [==============================] - 0s 459us/step - loss: 581.9318 - mse: 581.9318\n",
      "Epoch 336/500\n",
      "41/41 [==============================] - 0s 470us/step - loss: 581.9318 - mse: 581.9318\n",
      "Epoch 337/500\n",
      "41/41 [==============================] - 0s 467us/step - loss: 581.9316 - mse: 581.9316\n",
      "Epoch 338/500\n",
      "41/41 [==============================] - 0s 470us/step - loss: 581.9317 - mse: 581.9317\n",
      "Epoch 339/500\n",
      "41/41 [==============================] - 0s 464us/step - loss: 581.9316 - mse: 581.9316\n",
      "Epoch 340/500\n",
      "41/41 [==============================] - 0s 457us/step - loss: 581.9316 - mse: 581.9316\n",
      "Epoch 341/500\n",
      "41/41 [==============================] - 0s 445us/step - loss: 581.9318 - mse: 581.9318\n",
      "Epoch 342/500\n",
      "41/41 [==============================] - 0s 470us/step - loss: 581.9316 - mse: 581.9317\n",
      "Epoch 343/500\n",
      "41/41 [==============================] - 0s 458us/step - loss: 581.9316 - mse: 581.9316\n",
      "Epoch 344/500\n",
      "41/41 [==============================] - 0s 478us/step - loss: 581.9316 - mse: 581.9316\n",
      "Epoch 345/500\n",
      "41/41 [==============================] - 0s 485us/step - loss: 581.9318 - mse: 581.9318\n",
      "Epoch 346/500\n",
      "41/41 [==============================] - 0s 456us/step - loss: 581.9318 - mse: 581.9318\n",
      "Epoch 347/500\n",
      "41/41 [==============================] - 0s 464us/step - loss: 581.9316 - mse: 581.9316\n",
      "Epoch 348/500\n",
      "41/41 [==============================] - 0s 488us/step - loss: 581.9316 - mse: 581.9316\n",
      "Epoch 349/500\n",
      "41/41 [==============================] - 0s 496us/step - loss: 581.9318 - mse: 581.9318\n",
      "Epoch 350/500\n",
      "41/41 [==============================] - 0s 459us/step - loss: 581.9316 - mse: 581.9316\n",
      "Epoch 351/500\n",
      "41/41 [==============================] - 0s 487us/step - loss: 581.9316 - mse: 581.9317\n",
      "Epoch 352/500\n",
      "41/41 [==============================] - 0s 477us/step - loss: 581.9316 - mse: 581.9316\n",
      "Epoch 353/500\n",
      "41/41 [==============================] - 0s 478us/step - loss: 581.9317 - mse: 581.9317\n",
      "Epoch 354/500\n",
      "41/41 [==============================] - 0s 474us/step - loss: 581.9316 - mse: 581.9316\n",
      "Epoch 355/500\n",
      "41/41 [==============================] - 0s 458us/step - loss: 581.9317 - mse: 581.9317\n",
      "Epoch 356/500\n",
      "41/41 [==============================] - 0s 472us/step - loss: 581.9316 - mse: 581.9316\n",
      "Epoch 357/500\n",
      "41/41 [==============================] - 0s 475us/step - loss: 581.9317 - mse: 581.9317\n",
      "Epoch 358/500\n",
      "41/41 [==============================] - 0s 462us/step - loss: 581.9317 - mse: 581.9317\n",
      "Epoch 359/500\n",
      "41/41 [==============================] - 0s 467us/step - loss: 581.9316 - mse: 581.9316\n",
      "Epoch 360/500\n",
      "41/41 [==============================] - 0s 453us/step - loss: 581.9317 - mse: 581.9317\n",
      "Epoch 361/500\n",
      "41/41 [==============================] - 0s 445us/step - loss: 581.9316 - mse: 581.9316\n",
      "Epoch 362/500\n",
      "41/41 [==============================] - 0s 444us/step - loss: 581.9316 - mse: 581.9316\n",
      "Epoch 363/500\n",
      "41/41 [==============================] - 0s 477us/step - loss: 581.9318 - mse: 581.9318\n",
      "Epoch 364/500\n",
      "41/41 [==============================] - 0s 460us/step - loss: 581.9316 - mse: 581.9316\n",
      "Epoch 365/500\n",
      "41/41 [==============================] - 0s 458us/step - loss: 581.9318 - mse: 581.9318\n",
      "Epoch 366/500\n",
      "41/41 [==============================] - 0s 453us/step - loss: 581.9316 - mse: 581.9316\n",
      "Epoch 367/500\n",
      "41/41 [==============================] - 0s 448us/step - loss: 581.9317 - mse: 581.9317\n",
      "Epoch 368/500\n",
      "41/41 [==============================] - 0s 443us/step - loss: 581.9316 - mse: 581.9316\n",
      "Epoch 369/500\n",
      "41/41 [==============================] - 0s 455us/step - loss: 581.9317 - mse: 581.9317\n",
      "Epoch 370/500\n",
      "41/41 [==============================] - 0s 436us/step - loss: 581.9317 - mse: 581.9317\n",
      "Epoch 371/500\n",
      "41/41 [==============================] - 0s 453us/step - loss: 581.9316 - mse: 581.9316\n",
      "Epoch 372/500\n",
      "41/41 [==============================] - 0s 456us/step - loss: 581.9317 - mse: 581.9317\n",
      "Epoch 373/500\n",
      "41/41 [==============================] - 0s 458us/step - loss: 581.9316 - mse: 581.9316\n",
      "Epoch 374/500\n",
      "41/41 [==============================] - 0s 459us/step - loss: 581.9316 - mse: 581.9316\n",
      "Epoch 375/500\n",
      "41/41 [==============================] - 0s 455us/step - loss: 581.9316 - mse: 581.9316\n",
      "Epoch 376/500\n",
      "41/41 [==============================] - 0s 463us/step - loss: 581.9316 - mse: 581.9316\n",
      "Epoch 377/500\n",
      "41/41 [==============================] - 0s 455us/step - loss: 581.9316 - mse: 581.9316\n",
      "Epoch 378/500\n",
      "41/41 [==============================] - 0s 454us/step - loss: 581.9316 - mse: 581.9316\n",
      "Epoch 379/500\n",
      "41/41 [==============================] - 0s 451us/step - loss: 581.9316 - mse: 581.9316\n",
      "Epoch 380/500\n",
      "41/41 [==============================] - 0s 465us/step - loss: 581.9316 - mse: 581.9316\n",
      "Epoch 381/500\n",
      "41/41 [==============================] - 0s 449us/step - loss: 581.9317 - mse: 581.9317\n",
      "Epoch 382/500\n",
      "41/41 [==============================] - 0s 476us/step - loss: 581.9317 - mse: 581.9317\n",
      "Epoch 383/500\n",
      "41/41 [==============================] - 0s 467us/step - loss: 581.9317 - mse: 581.9317\n",
      "Epoch 384/500\n",
      "41/41 [==============================] - 0s 512us/step - loss: 581.9317 - mse: 581.9317\n",
      "Epoch 385/500\n",
      "41/41 [==============================] - 0s 449us/step - loss: 581.9316 - mse: 581.9316\n",
      "Epoch 386/500\n",
      "41/41 [==============================] - 0s 498us/step - loss: 581.9316 - mse: 581.9316\n",
      "Epoch 387/500\n",
      "41/41 [==============================] - 0s 436us/step - loss: 581.9316 - mse: 581.9316\n",
      "Epoch 388/500\n",
      "41/41 [==============================] - 0s 451us/step - loss: 581.9318 - mse: 581.9318\n",
      "Epoch 389/500\n",
      "41/41 [==============================] - 0s 454us/step - loss: 581.9318 - mse: 581.9318\n",
      "Epoch 390/500\n",
      "41/41 [==============================] - 0s 439us/step - loss: 581.9318 - mse: 581.9318\n",
      "Epoch 391/500\n",
      "41/41 [==============================] - 0s 434us/step - loss: 581.9316 - mse: 581.9316\n",
      "Epoch 392/500\n",
      "41/41 [==============================] - 0s 442us/step - loss: 581.9316 - mse: 581.9316\n",
      "Epoch 393/500\n",
      "41/41 [==============================] - 0s 432us/step - loss: 581.9316 - mse: 581.9316\n",
      "Epoch 394/500\n",
      "41/41 [==============================] - 0s 473us/step - loss: 581.9316 - mse: 581.9316\n",
      "Epoch 395/500\n",
      "41/41 [==============================] - 0s 477us/step - loss: 581.9316 - mse: 581.9316\n",
      "Epoch 396/500\n",
      "41/41 [==============================] - 0s 452us/step - loss: 581.9316 - mse: 581.9316\n",
      "Epoch 397/500\n",
      "41/41 [==============================] - 0s 438us/step - loss: 581.9317 - mse: 581.9317\n",
      "Epoch 398/500\n",
      "41/41 [==============================] - 0s 442us/step - loss: 581.9317 - mse: 581.9317\n",
      "Epoch 399/500\n",
      "41/41 [==============================] - 0s 452us/step - loss: 581.9318 - mse: 581.9318\n",
      "Epoch 400/500\n",
      "41/41 [==============================] - 0s 472us/step - loss: 581.9317 - mse: 581.9317\n",
      "Epoch 401/500\n",
      "41/41 [==============================] - 0s 446us/step - loss: 581.9316 - mse: 581.9316\n",
      "Epoch 402/500\n",
      "41/41 [==============================] - 0s 454us/step - loss: 581.9316 - mse: 581.9316\n",
      "Epoch 403/500\n",
      "41/41 [==============================] - 0s 485us/step - loss: 581.9316 - mse: 581.9316\n",
      "Epoch 404/500\n",
      "41/41 [==============================] - 0s 446us/step - loss: 581.9317 - mse: 581.9317\n",
      "Epoch 405/500\n",
      "41/41 [==============================] - 0s 416us/step - loss: 581.9316 - mse: 581.9316\n",
      "Epoch 406/500\n",
      "41/41 [==============================] - 0s 430us/step - loss: 581.9316 - mse: 581.9316\n",
      "Epoch 407/500\n",
      "41/41 [==============================] - 0s 482us/step - loss: 581.9316 - mse: 581.9316\n",
      "Epoch 408/500\n",
      "41/41 [==============================] - 0s 478us/step - loss: 581.9317 - mse: 581.9317\n",
      "Epoch 409/500\n",
      "41/41 [==============================] - 0s 458us/step - loss: 581.9316 - mse: 581.9316\n",
      "Epoch 410/500\n",
      "41/41 [==============================] - 0s 457us/step - loss: 581.9317 - mse: 581.9317\n",
      "Epoch 411/500\n",
      "41/41 [==============================] - 0s 453us/step - loss: 581.9318 - mse: 581.9318\n",
      "Epoch 412/500\n",
      "41/41 [==============================] - 0s 453us/step - loss: 581.9318 - mse: 581.9318\n",
      "Epoch 413/500\n",
      "41/41 [==============================] - 0s 438us/step - loss: 581.9316 - mse: 581.9316\n",
      "Epoch 414/500\n",
      "41/41 [==============================] - 0s 471us/step - loss: 581.9316 - mse: 581.9316\n",
      "Epoch 415/500\n",
      "41/41 [==============================] - 0s 459us/step - loss: 581.9316 - mse: 581.9316\n",
      "Epoch 416/500\n",
      "41/41 [==============================] - 0s 461us/step - loss: 581.9316 - mse: 581.9316\n",
      "Epoch 417/500\n",
      "41/41 [==============================] - 0s 476us/step - loss: 581.9316 - mse: 581.9316\n",
      "Epoch 418/500\n",
      "41/41 [==============================] - 0s 489us/step - loss: 581.9316 - mse: 581.9316\n",
      "Epoch 419/500\n",
      "41/41 [==============================] - 0s 460us/step - loss: 581.9318 - mse: 581.9318\n",
      "Epoch 420/500\n",
      "41/41 [==============================] - 0s 462us/step - loss: 581.9318 - mse: 581.9318\n",
      "Epoch 421/500\n",
      "41/41 [==============================] - 0s 478us/step - loss: 581.9318 - mse: 581.9318\n",
      "Epoch 422/500\n",
      "41/41 [==============================] - 0s 451us/step - loss: 581.9317 - mse: 581.9317\n",
      "Epoch 423/500\n",
      "41/41 [==============================] - 0s 454us/step - loss: 581.9317 - mse: 581.9317\n",
      "Epoch 424/500\n",
      "41/41 [==============================] - 0s 464us/step - loss: 581.9317 - mse: 581.9317\n",
      "Epoch 425/500\n",
      "41/41 [==============================] - 0s 455us/step - loss: 581.9316 - mse: 581.9316\n",
      "Epoch 426/500\n",
      "41/41 [==============================] - 0s 429us/step - loss: 581.9316 - mse: 581.9316\n",
      "Epoch 427/500\n",
      "41/41 [==============================] - 0s 460us/step - loss: 581.9318 - mse: 581.9318\n",
      "Epoch 428/500\n",
      "41/41 [==============================] - 0s 475us/step - loss: 581.9316 - mse: 581.9316\n",
      "Epoch 429/500\n",
      "41/41 [==============================] - 0s 433us/step - loss: 581.9318 - mse: 581.9317\n",
      "Epoch 430/500\n",
      "41/41 [==============================] - 0s 456us/step - loss: 581.9318 - mse: 581.9318\n",
      "Epoch 431/500\n",
      "41/41 [==============================] - 0s 495us/step - loss: 581.9318 - mse: 581.9318\n",
      "Epoch 432/500\n",
      "41/41 [==============================] - 0s 454us/step - loss: 581.9316 - mse: 581.9316\n",
      "Epoch 433/500\n",
      "41/41 [==============================] - 0s 451us/step - loss: 581.9317 - mse: 581.9317\n",
      "Epoch 434/500\n",
      "41/41 [==============================] - 0s 452us/step - loss: 581.9318 - mse: 581.9318\n",
      "Epoch 435/500\n",
      "41/41 [==============================] - 0s 455us/step - loss: 581.9318 - mse: 581.9318\n",
      "Epoch 436/500\n",
      "41/41 [==============================] - 0s 460us/step - loss: 581.9316 - mse: 581.9316\n",
      "Epoch 437/500\n",
      "41/41 [==============================] - 0s 485us/step - loss: 581.9318 - mse: 581.9318\n",
      "Epoch 438/500\n",
      "41/41 [==============================] - 0s 467us/step - loss: 581.9317 - mse: 581.9317\n",
      "Epoch 439/500\n",
      "41/41 [==============================] - 0s 464us/step - loss: 581.9318 - mse: 581.9318\n",
      "Epoch 440/500\n",
      "41/41 [==============================] - 0s 461us/step - loss: 581.9317 - mse: 581.9317\n",
      "Epoch 441/500\n",
      "41/41 [==============================] - 0s 444us/step - loss: 581.9318 - mse: 581.9316\n",
      "Epoch 442/500\n",
      "41/41 [==============================] - 0s 459us/step - loss: 581.9316 - mse: 581.9316\n",
      "Epoch 443/500\n",
      "41/41 [==============================] - 0s 456us/step - loss: 581.9318 - mse: 581.9318\n",
      "Epoch 444/500\n",
      "41/41 [==============================] - 0s 465us/step - loss: 581.9317 - mse: 581.9317\n",
      "Epoch 445/500\n",
      "41/41 [==============================] - 0s 462us/step - loss: 581.9316 - mse: 581.9316\n",
      "Epoch 446/500\n",
      "41/41 [==============================] - 0s 468us/step - loss: 581.9318 - mse: 581.9318\n",
      "Epoch 447/500\n",
      "41/41 [==============================] - 0s 461us/step - loss: 581.9316 - mse: 581.9316\n",
      "Epoch 448/500\n",
      "41/41 [==============================] - 0s 448us/step - loss: 581.9318 - mse: 581.9318\n",
      "Epoch 449/500\n",
      "41/41 [==============================] - 0s 466us/step - loss: 581.9318 - mse: 581.9318\n",
      "Epoch 450/500\n",
      "41/41 [==============================] - 0s 466us/step - loss: 581.9318 - mse: 581.9318\n",
      "Epoch 451/500\n",
      "41/41 [==============================] - 0s 447us/step - loss: 581.9318 - mse: 581.9318\n",
      "Epoch 452/500\n",
      "41/41 [==============================] - 0s 464us/step - loss: 581.9316 - mse: 581.9316\n",
      "Epoch 453/500\n",
      "41/41 [==============================] - 0s 475us/step - loss: 581.9317 - mse: 581.9317\n",
      "Epoch 454/500\n",
      "41/41 [==============================] - 0s 452us/step - loss: 581.9317 - mse: 581.9317\n",
      "Epoch 455/500\n",
      "41/41 [==============================] - 0s 487us/step - loss: 581.9316 - mse: 581.9316\n",
      "Epoch 456/500\n",
      "41/41 [==============================] - 0s 460us/step - loss: 581.9316 - mse: 581.9316\n",
      "Epoch 457/500\n",
      "41/41 [==============================] - 0s 441us/step - loss: 581.9315 - mse: 581.9315\n",
      "Epoch 458/500\n",
      "41/41 [==============================] - 0s 438us/step - loss: 581.9317 - mse: 581.9317\n",
      "Epoch 459/500\n",
      "41/41 [==============================] - 0s 449us/step - loss: 581.9317 - mse: 581.9317\n",
      "Epoch 460/500\n",
      "41/41 [==============================] - 0s 460us/step - loss: 581.9317 - mse: 581.9317\n",
      "Epoch 461/500\n",
      "41/41 [==============================] - 0s 458us/step - loss: 581.9316 - mse: 581.9316\n",
      "Epoch 462/500\n",
      "41/41 [==============================] - 0s 453us/step - loss: 581.9317 - mse: 581.9317\n",
      "Epoch 463/500\n",
      "41/41 [==============================] - 0s 432us/step - loss: 581.9317 - mse: 581.9317\n",
      "Epoch 464/500\n",
      "41/41 [==============================] - 0s 451us/step - loss: 581.9317 - mse: 581.9317\n",
      "Epoch 465/500\n",
      "41/41 [==============================] - 0s 518us/step - loss: 581.9315 - mse: 581.9315\n",
      "Epoch 466/500\n",
      "41/41 [==============================] - 0s 454us/step - loss: 581.9318 - mse: 581.9318\n",
      "Epoch 467/500\n",
      "41/41 [==============================] - 0s 452us/step - loss: 581.9316 - mse: 581.9316\n",
      "Epoch 468/500\n",
      "41/41 [==============================] - 0s 447us/step - loss: 581.9316 - mse: 581.9316\n",
      "Epoch 469/500\n",
      "41/41 [==============================] - 0s 448us/step - loss: 581.9318 - mse: 581.9318\n",
      "Epoch 470/500\n",
      "41/41 [==============================] - 0s 432us/step - loss: 581.9316 - mse: 581.9316\n",
      "Epoch 471/500\n",
      "41/41 [==============================] - 0s 473us/step - loss: 581.9317 - mse: 581.9317\n",
      "Epoch 472/500\n",
      "41/41 [==============================] - 0s 447us/step - loss: 581.9316 - mse: 581.9316\n",
      "Epoch 473/500\n",
      "41/41 [==============================] - 0s 449us/step - loss: 581.9316 - mse: 581.9316\n",
      "Epoch 474/500\n",
      "41/41 [==============================] - 0s 436us/step - loss: 581.9318 - mse: 581.9317\n",
      "Epoch 475/500\n",
      "41/41 [==============================] - 0s 405us/step - loss: 581.9317 - mse: 581.9317\n",
      "Epoch 476/500\n",
      "41/41 [==============================] - 0s 449us/step - loss: 581.9318 - mse: 581.9318\n",
      "Epoch 477/500\n",
      "41/41 [==============================] - 0s 478us/step - loss: 581.9317 - mse: 581.9317\n",
      "Epoch 478/500\n",
      "41/41 [==============================] - 0s 443us/step - loss: 581.9318 - mse: 581.9318\n",
      "Epoch 479/500\n",
      "41/41 [==============================] - 0s 446us/step - loss: 581.9316 - mse: 581.9316\n",
      "Epoch 480/500\n",
      "41/41 [==============================] - 0s 453us/step - loss: 581.9316 - mse: 581.9316\n",
      "Epoch 481/500\n",
      "41/41 [==============================] - 0s 447us/step - loss: 581.9317 - mse: 581.9317\n",
      "Epoch 482/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - 0s 439us/step - loss: 581.9317 - mse: 581.9317\n",
      "Epoch 483/500\n",
      "41/41 [==============================] - 0s 459us/step - loss: 581.9316 - mse: 581.9316\n",
      "Epoch 484/500\n",
      "41/41 [==============================] - 0s 441us/step - loss: 581.9316 - mse: 581.9316\n",
      "Epoch 485/500\n",
      "41/41 [==============================] - 0s 478us/step - loss: 581.9317 - mse: 581.9317\n",
      "Epoch 486/500\n",
      "41/41 [==============================] - 0s 445us/step - loss: 581.9316 - mse: 581.9316\n",
      "Epoch 487/500\n",
      "41/41 [==============================] - 0s 489us/step - loss: 581.9316 - mse: 581.9316\n",
      "Epoch 488/500\n",
      "41/41 [==============================] - 0s 452us/step - loss: 581.9317 - mse: 581.9317\n",
      "Epoch 489/500\n",
      "41/41 [==============================] - 0s 460us/step - loss: 581.9316 - mse: 581.9316\n",
      "Epoch 490/500\n",
      "41/41 [==============================] - 0s 449us/step - loss: 581.9317 - mse: 581.9317\n",
      "Epoch 491/500\n",
      "41/41 [==============================] - 0s 446us/step - loss: 581.9317 - mse: 581.9317\n",
      "Epoch 492/500\n",
      "41/41 [==============================] - 0s 453us/step - loss: 581.9318 - mse: 581.9318\n",
      "Epoch 493/500\n",
      "41/41 [==============================] - 0s 470us/step - loss: 581.9318 - mse: 581.9318\n",
      "Epoch 494/500\n",
      "41/41 [==============================] - 0s 445us/step - loss: 581.9317 - mse: 581.9317\n",
      "Epoch 495/500\n",
      "41/41 [==============================] - 0s 459us/step - loss: 581.9318 - mse: 581.9318\n",
      "Epoch 496/500\n",
      "41/41 [==============================] - 0s 453us/step - loss: 581.9318 - mse: 581.9318\n",
      "Epoch 497/500\n",
      "41/41 [==============================] - 0s 472us/step - loss: 581.9316 - mse: 581.9316\n",
      "Epoch 498/500\n",
      "41/41 [==============================] - 0s 457us/step - loss: 581.9317 - mse: 581.9317\n",
      "Epoch 499/500\n",
      "41/41 [==============================] - 0s 435us/step - loss: 581.9316 - mse: 581.9316\n",
      "Epoch 500/500\n",
      "41/41 [==============================] - 0s 457us/step - loss: 581.9318 - mse: 581.9318\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f4008384100>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, batch_size = 10, epochs = 500, verbose = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Evaluation\n",
    "- Keras model can be evaluated with evaluate() function\n",
    "- Evaluation results are contained in a list\n",
    "    - Doc (metrics): https://keras.io/metrics/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 688us/step - loss: 611.4797 - mse: 611.4797\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['loss', 'mse']\n",
      "[611.4796752929688, 611.4796752929688]\n",
      "loss:  611.4796752929688\n",
      "mse:  611.4796752929688\n"
     ]
    }
   ],
   "source": [
    "print(model.metrics_names)     # list of metric names the model is employing\n",
    "print(results)                 # actual figure of metrics computed\n",
    "print('loss: ', results[0])\n",
    "print('mse: ', results[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Breast cancer detection "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP for classification tasks\n",
    "- When the target (**y**) is discrete (categorical)\n",
    "- For loss function, cross-entropy is used and for evaluation metric, accuracy is commonly used\n",
    "\n",
    "### Dataset Description\n",
    "- Breast cancer dataset has total 569 data instances (212 malign, 357 benign instances)\n",
    "- 30 attributes (features) to predict the binary class (M/B)\n",
    "- Doc: http://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_breast_cancer.html#sklearn.datasets.load_breast_cancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "whole_data = load_breast_cancer()\n",
    "\n",
    "X_data = whole_data.data\n",
    "y_data = whole_data.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_data, y_data, test_size = 0.3, random_state = 7) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(398, 30)\n",
      "[1.305e+01 1.931e+01 8.261e+01 5.272e+02 8.060e-02 3.789e-02 6.920e-04\n",
      " 4.167e-03 1.819e-01 5.501e-02 4.040e-01 1.214e+00 2.595e+00 3.296e+01\n",
      " 7.491e-03 8.593e-03 6.920e-04 4.167e-03 2.190e-02 2.990e-03 1.423e+01\n",
      " 2.225e+01 9.024e+01 6.241e+02 1.021e-01 6.191e-02 1.845e-03 1.111e-02\n",
      " 2.439e-01 6.289e-02]\n",
      "(171, 30)\n",
      "(398,)\n",
      "(171,)\n",
      "Lebels: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
       "       0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0,\n",
       "       1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
       "       1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1,\n",
       "       1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0,\n",
       "       1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_train[1,:])\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n",
    "print('Lebels: ')\n",
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_6 (Dense)              (None, 10)                310       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 1)                 11        \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 541\n",
      "Trainable params: 541\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Dense\n",
    "model = Sequential()\n",
    "\n",
    "# Keras model with two hidden layer with 10 neurons each \n",
    "model.add(Dense(10, input_shape = (30,)))    # Input layer => input_shape should be explicitly designated\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(Dense(10))                         # Hidden layer => only output dimension should be designated\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(Dense(10))                         # Hidden layer => only output dimension should be designated\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(Dense(1))                          # Output layer => output dimension = 1 since it is regression problem\n",
    "model.add(Activation('sigmoid'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Compile and Training the model\n",
    "- Training the model with training data provided"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.6895 - accuracy: 0.6761\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.6835 - accuracy: 0.6402\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 970us/step - loss: 0.6806 - accuracy: 0.6031\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.6780 - accuracy: 0.5918\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.6751 - accuracy: 0.6059\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.6734 - accuracy: 0.6054\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.6684 - accuracy: 0.6276\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.6691 - accuracy: 0.6125\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.6652 - accuracy: 0.6274\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.6623 - accuracy: 0.6340\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.6756 - accuracy: 0.5709\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.6571 - accuracy: 0.6460\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.6753 - accuracy: 0.5694\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.6676 - accuracy: 0.5980\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.6641 - accuracy: 0.6097\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.6622 - accuracy: 0.6150\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.6653 - accuracy: 0.6021\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.6641 - accuracy: 0.6049\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.6575 - accuracy: 0.6253\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.6625 - accuracy: 0.6090\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.6589 - accuracy: 0.6176\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.6639 - accuracy: 0.6041\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.6574 - accuracy: 0.6228\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.6628 - accuracy: 0.6065\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.6639 - accuracy: 0.6029\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.6542 - accuracy: 0.6300\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.6665 - accuracy: 0.5953\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.6532 - accuracy: 0.6302\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.6530 - accuracy: 0.6311\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.6579 - accuracy: 0.6171\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.6725 - accuracy: 0.5804\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.6488 - accuracy: 0.6399\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.6573 - accuracy: 0.6189\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.6756 - accuracy: 0.5704\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.6578 - accuracy: 0.6172\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.6674 - accuracy: 0.5930\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.6621 - accuracy: 0.6063\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.6734 - accuracy: 0.5769\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.6582 - accuracy: 0.6153\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.6630 - accuracy: 0.6029\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.6641 - accuracy: 0.6002\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.6631 - accuracy: 0.6032\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.6694 - accuracy: 0.5877\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.6468 - accuracy: 0.6420\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.6579 - accuracy: 0.6145\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.6604 - accuracy: 0.6088\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.6554 - accuracy: 0.6213\n",
      "Epoch 48/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.6503 - accuracy: 0.6337\n",
      "Epoch 49/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.6430 - accuracy: 0.6511\n",
      "Epoch 50/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.6580 - accuracy: 0.6132\n",
      "Epoch 51/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.6667 - accuracy: 0.5921\n",
      "Epoch 52/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.6743 - accuracy: 0.5730\n",
      "Epoch 53/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.6574 - accuracy: 0.6148\n",
      "Epoch 54/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.6494 - accuracy: 0.6344\n",
      "Epoch 55/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.6635 - accuracy: 0.6001\n",
      "Epoch 56/100\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.6586 - accuracy: 0.6116\n",
      "Epoch 57/100\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.6676 - accuracy: 0.5902\n",
      "Epoch 58/100\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.6621 - accuracy: 0.6023\n",
      "Epoch 59/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.6662 - accuracy: 0.5927\n",
      "Epoch 60/100\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.6556 - accuracy: 0.6166\n",
      "Epoch 61/100\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.6722 - accuracy: 0.5787\n",
      "Epoch 62/100\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.6612 - accuracy: 0.6045\n",
      "Epoch 63/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.6672 - accuracy: 0.5915\n",
      "Epoch 64/100\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.6642 - accuracy: 0.5962\n",
      "Epoch 65/100\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.6579 - accuracy: 0.6136\n",
      "Epoch 66/100\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.6650 - accuracy: 0.5953\n",
      "Epoch 67/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.6625 - accuracy: 0.6029\n",
      "Epoch 68/100\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.6567 - accuracy: 0.6139\n",
      "Epoch 69/100\n",
      "8/8 [==============================] - 0s 880us/step - loss: 0.6645 - accuracy: 0.5954\n",
      "Epoch 70/100\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.6549 - accuracy: 0.6181\n",
      "Epoch 71/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.6493 - accuracy: 0.6325\n",
      "Epoch 72/100\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.6590 - accuracy: 0.6094\n",
      "Epoch 73/100\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.6542 - accuracy: 0.6206\n",
      "Epoch 74/100\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.6611 - accuracy: 0.6030\n",
      "Epoch 75/100\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.6614 - accuracy: 0.6024\n",
      "Epoch 76/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.6539 - accuracy: 0.6188\n",
      "Epoch 77/100\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.6559 - accuracy: 0.6159\n",
      "Epoch 78/100\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.6768 - accuracy: 0.5649\n",
      "Epoch 79/100\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.6558 - accuracy: 0.6155\n",
      "Epoch 80/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.6496 - accuracy: 0.6304\n",
      "Epoch 81/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.6621 - accuracy: 0.6014\n",
      "Epoch 82/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.6585 - accuracy: 0.6091\n",
      "Epoch 83/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.6514 - accuracy: 0.6248\n",
      "Epoch 84/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.6602 - accuracy: 0.6050\n",
      "Epoch 85/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.6646 - accuracy: 0.5935\n",
      "Epoch 86/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.6455 - accuracy: 0.6400\n",
      "Epoch 87/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.6443 - accuracy: 0.6418\n",
      "Epoch 88/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.6707 - accuracy: 0.5790\n",
      "Epoch 89/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.6506 - accuracy: 0.6254\n",
      "Epoch 90/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.6471 - accuracy: 0.6355\n",
      "Epoch 91/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.6560 - accuracy: 0.6152\n",
      "Epoch 92/100\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.6428 - accuracy: 0.6435\n",
      "Epoch 93/100\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.6555 - accuracy: 0.6143\n",
      "Epoch 94/100\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.6536 - accuracy: 0.6192\n",
      "Epoch 95/100\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.6588 - accuracy: 0.6063\n",
      "Epoch 96/100\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.6539 - accuracy: 0.6172\n",
      "Epoch 97/100\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.6528 - accuracy: 0.6208\n",
      "Epoch 98/100\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.6546 - accuracy: 0.6172\n",
      "Epoch 99/100\n",
      "8/8 [==============================] - 0s 829us/step - loss: 0.6679 - accuracy: 0.5845\n",
      "Epoch 100/100\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.6649 - accuracy: 0.5930\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fbc182b1310>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras import optimizers\n",
    "sgd = optimizers.SGD(lr = 0.01)    # stochastic gradient descent optimizer\n",
    "model.compile(optimizer = sgd, loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "model.fit(X_train, y_train, batch_size = 50, epochs = 100, verbose = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Evaluation\n",
    "- Keras model can be evaluated with evaluate() function\n",
    "- Evaluation results are contained in a list\n",
    "    - Doc (metrics): https://keras.io/metrics/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 962us/step - loss: 0.6288 - accuracy: 0.6784\n",
      "['loss', 'accuracy']\n",
      "[0.6288270354270935, 0.6783625483512878]\n",
      "loss:  0.6288270354270935\n",
      "accuracy:  0.6783625483512878\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(X_test, y_test)\n",
    "print(model.metrics_names)     # list of metric names the model is employing\n",
    "print(results)                 # actual figure of metrics computed\n",
    "print('loss: ', results[0])\n",
    "print('accuracy: ', results[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ddiabetes detection\n",
    " - Pima Indians onset of diabetes dataset. \n",
    " - A standard machine learning dataset from the UCI Machine Learning repository. \n",
    " - It describes patient medical record data for Pima Indians and whether they had an onset of \n",
    "diabetes within five years.\n",
    "Features:\n",
    "    Pregnancies,\n",
    "    Glucose,\n",
    "    BloodPressure,\n",
    "    SkinThickness,\n",
    "    Insulin,\n",
    "    BMI,\n",
    "    DiabetesPedigreeFunction,\n",
    "    Age,\n",
    "    Class\n",
    " - A binary classification problem (onset of diabetes as 1 or not as 0). \n",
    " - Database details :  https://www.kaggle.com/kumargh/pimaindiansdiabetescsv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 12)                108       \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 8)                 104       \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 221\n",
      "Trainable params: 221\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from numpy import loadtxt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "# load the dataset\n",
    "dataset = loadtxt('pima-indians-diabetes.csv', delimiter=',')\n",
    "# split into input (X) and output (y) variables\n",
    "X = dataset[:,0:8]\n",
    "y = dataset[:,8]\n",
    "# define the keras model\n",
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=8, activation='sigmoid'))\n",
    "model.add(Dense(8, activation='sigmoid'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile and Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "77/77 [==============================] - 0s 932us/step - loss: 0.6758 - accuracy: 0.6197\n",
      "Epoch 2/150\n",
      "77/77 [==============================] - 0s 900us/step - loss: 0.6659 - accuracy: 0.6372\n",
      "Epoch 3/150\n",
      "77/77 [==============================] - 0s 879us/step - loss: 0.6508 - accuracy: 0.6569\n",
      "Epoch 4/150\n",
      "77/77 [==============================] - 0s 943us/step - loss: 0.6617 - accuracy: 0.6298\n",
      "Epoch 5/150\n",
      "77/77 [==============================] - 0s 826us/step - loss: 0.6599 - accuracy: 0.6361\n",
      "Epoch 6/150\n",
      "77/77 [==============================] - 0s 900us/step - loss: 0.6419 - accuracy: 0.6616\n",
      "Epoch 7/150\n",
      "77/77 [==============================] - 0s 900us/step - loss: 0.6690 - accuracy: 0.6194\n",
      "Epoch 8/150\n",
      "77/77 [==============================] - 0s 948us/step - loss: 0.6423 - accuracy: 0.6580\n",
      "Epoch 9/150\n",
      "77/77 [==============================] - 0s 851us/step - loss: 0.6457 - accuracy: 0.6484\n",
      "Epoch 10/150\n",
      "77/77 [==============================] - 0s 953us/step - loss: 0.6223 - accuracy: 0.6831\n",
      "Epoch 11/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6303 - accuracy: 0.6701\n",
      "Epoch 12/150\n",
      "77/77 [==============================] - 0s 918us/step - loss: 0.6653 - accuracy: 0.6141\n",
      "Epoch 13/150\n",
      "77/77 [==============================] - 0s 982us/step - loss: 0.6341 - accuracy: 0.6615\n",
      "Epoch 14/150\n",
      "77/77 [==============================] - 0s 890us/step - loss: 0.6390 - accuracy: 0.6555\n",
      "Epoch 15/150\n",
      "77/77 [==============================] - 0s 975us/step - loss: 0.6331 - accuracy: 0.6588\n",
      "Epoch 16/150\n",
      "77/77 [==============================] - 0s 923us/step - loss: 0.6293 - accuracy: 0.6682\n",
      "Epoch 17/150\n",
      "77/77 [==============================] - 0s 891us/step - loss: 0.6558 - accuracy: 0.6307\n",
      "Epoch 18/150\n",
      "77/77 [==============================] - 0s 881us/step - loss: 0.6250 - accuracy: 0.6786\n",
      "Epoch 19/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6403 - accuracy: 0.6517\n",
      "Epoch 20/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6458 - accuracy: 0.6481\n",
      "Epoch 21/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6374 - accuracy: 0.6512\n",
      "Epoch 22/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6252 - accuracy: 0.6700\n",
      "Epoch 23/150\n",
      "77/77 [==============================] - 0s 904us/step - loss: 0.6439 - accuracy: 0.6387\n",
      "Epoch 24/150\n",
      "77/77 [==============================] - 0s 918us/step - loss: 0.6347 - accuracy: 0.6571\n",
      "Epoch 25/150\n",
      "77/77 [==============================] - 0s 913us/step - loss: 0.6264 - accuracy: 0.6701\n",
      "Epoch 26/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6398 - accuracy: 0.6487\n",
      "Epoch 27/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6307 - accuracy: 0.6646\n",
      "Epoch 28/150\n",
      "77/77 [==============================] - 0s 924us/step - loss: 0.6359 - accuracy: 0.6550\n",
      "Epoch 29/150\n",
      "77/77 [==============================] - 0s 966us/step - loss: 0.6264 - accuracy: 0.6680\n",
      "Epoch 30/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6365 - accuracy: 0.6589\n",
      "Epoch 31/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6303 - accuracy: 0.6643\n",
      "Epoch 32/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6373 - accuracy: 0.6547\n",
      "Epoch 33/150\n",
      "77/77 [==============================] - 0s 868us/step - loss: 0.6259 - accuracy: 0.6719\n",
      "Epoch 34/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6298 - accuracy: 0.6640\n",
      "Epoch 35/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6272 - accuracy: 0.6661\n",
      "Epoch 36/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6426 - accuracy: 0.6427\n",
      "Epoch 37/150\n",
      "77/77 [==============================] - 0s 808us/step - loss: 0.6294 - accuracy: 0.6626\n",
      "Epoch 38/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6503 - accuracy: 0.6338\n",
      "Epoch 39/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6390 - accuracy: 0.6487\n",
      "Epoch 40/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6457 - accuracy: 0.6366\n",
      "Epoch 41/150\n",
      "77/77 [==============================] - 0s 936us/step - loss: 0.6065 - accuracy: 0.6953\n",
      "Epoch 42/150\n",
      "77/77 [==============================] - 0s 896us/step - loss: 0.6282 - accuracy: 0.6659\n",
      "Epoch 43/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6445 - accuracy: 0.6402\n",
      "Epoch 44/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6411 - accuracy: 0.6352\n",
      "Epoch 45/150\n",
      "77/77 [==============================] - 0s 894us/step - loss: 0.6515 - accuracy: 0.6231\n",
      "Epoch 46/150\n",
      "77/77 [==============================] - 0s 907us/step - loss: 0.6526 - accuracy: 0.6307\n",
      "Epoch 47/150\n",
      "77/77 [==============================] - 0s 956us/step - loss: 0.6118 - accuracy: 0.6845\n",
      "Epoch 48/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6239 - accuracy: 0.6668\n",
      "Epoch 49/150\n",
      "77/77 [==============================] - 0s 895us/step - loss: 0.6259 - accuracy: 0.6657\n",
      "Epoch 50/150\n",
      "77/77 [==============================] - 0s 994us/step - loss: 0.6425 - accuracy: 0.6447\n",
      "Epoch 51/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6322 - accuracy: 0.6542\n",
      "Epoch 52/150\n",
      "77/77 [==============================] - 0s 887us/step - loss: 0.6257 - accuracy: 0.6631\n",
      "Epoch 53/150\n",
      "77/77 [==============================] - 0s 965us/step - loss: 0.6382 - accuracy: 0.6455\n",
      "Epoch 54/150\n",
      "77/77 [==============================] - 0s 992us/step - loss: 0.6435 - accuracy: 0.6377\n",
      "Epoch 55/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6485 - accuracy: 0.6328\n",
      "Epoch 56/150\n",
      "77/77 [==============================] - 0s 893us/step - loss: 0.6390 - accuracy: 0.6379\n",
      "Epoch 57/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6502 - accuracy: 0.6225\n",
      "Epoch 58/150\n",
      "77/77 [==============================] - 0s 850us/step - loss: 0.6427 - accuracy: 0.6337\n",
      "Epoch 59/150\n",
      "77/77 [==============================] - 0s 891us/step - loss: 0.6215 - accuracy: 0.6657\n",
      "Epoch 60/150\n",
      "77/77 [==============================] - 0s 993us/step - loss: 0.6474 - accuracy: 0.6258\n",
      "Epoch 61/150\n",
      "77/77 [==============================] - 0s 886us/step - loss: 0.6290 - accuracy: 0.6550\n",
      "Epoch 62/150\n",
      "77/77 [==============================] - 0s 907us/step - loss: 0.6378 - accuracy: 0.6496\n",
      "Epoch 63/150\n",
      "77/77 [==============================] - 0s 905us/step - loss: 0.6450 - accuracy: 0.6316\n",
      "Epoch 64/150\n",
      "77/77 [==============================] - 0s 917us/step - loss: 0.6242 - accuracy: 0.6635\n",
      "Epoch 65/150\n",
      "77/77 [==============================] - 0s 951us/step - loss: 0.6256 - accuracy: 0.6579\n",
      "Epoch 66/150\n",
      "77/77 [==============================] - 0s 967us/step - loss: 0.6310 - accuracy: 0.6457\n",
      "Epoch 67/150\n",
      "77/77 [==============================] - 0s 954us/step - loss: 0.6261 - accuracy: 0.6605\n",
      "Epoch 68/150\n",
      "77/77 [==============================] - 0s 919us/step - loss: 0.6479 - accuracy: 0.6264\n",
      "Epoch 69/150\n",
      "77/77 [==============================] - 0s 901us/step - loss: 0.6312 - accuracy: 0.6512\n",
      "Epoch 70/150\n",
      "77/77 [==============================] - 0s 994us/step - loss: 0.6007 - accuracy: 0.6905\n",
      "Epoch 71/150\n",
      "77/77 [==============================] - 0s 957us/step - loss: 0.6378 - accuracy: 0.6408\n",
      "Epoch 72/150\n",
      "77/77 [==============================] - 0s 965us/step - loss: 0.6408 - accuracy: 0.6285\n",
      "Epoch 73/150\n",
      "77/77 [==============================] - 0s 916us/step - loss: 0.6398 - accuracy: 0.6280\n",
      "Epoch 74/150\n",
      "77/77 [==============================] - 0s 967us/step - loss: 0.6216 - accuracy: 0.6578\n",
      "Epoch 75/150\n",
      "77/77 [==============================] - 0s 949us/step - loss: 0.6266 - accuracy: 0.6541\n",
      "Epoch 76/150\n",
      "77/77 [==============================] - 0s 941us/step - loss: 0.6329 - accuracy: 0.6392\n",
      "Epoch 77/150\n",
      "77/77 [==============================] - 0s 930us/step - loss: 0.6274 - accuracy: 0.6559\n",
      "Epoch 78/150\n",
      "77/77 [==============================] - 0s 911us/step - loss: 0.6416 - accuracy: 0.6292\n",
      "Epoch 79/150\n",
      "77/77 [==============================] - 0s 908us/step - loss: 0.6285 - accuracy: 0.6510\n",
      "Epoch 80/150\n",
      "77/77 [==============================] - 0s 922us/step - loss: 0.6324 - accuracy: 0.6484\n",
      "Epoch 81/150\n",
      "77/77 [==============================] - 0s 881us/step - loss: 0.6333 - accuracy: 0.6395\n",
      "Epoch 82/150\n",
      "77/77 [==============================] - 0s 845us/step - loss: 0.6234 - accuracy: 0.6539\n",
      "Epoch 83/150\n",
      "77/77 [==============================] - 0s 867us/step - loss: 0.6176 - accuracy: 0.6616\n",
      "Epoch 84/150\n",
      "77/77 [==============================] - 0s 854us/step - loss: 0.6215 - accuracy: 0.6620\n",
      "Epoch 85/150\n",
      "77/77 [==============================] - 0s 852us/step - loss: 0.6298 - accuracy: 0.6490\n",
      "Epoch 86/150\n",
      "77/77 [==============================] - 0s 858us/step - loss: 0.6306 - accuracy: 0.6367\n",
      "Epoch 87/150\n",
      "77/77 [==============================] - 0s 869us/step - loss: 0.6204 - accuracy: 0.6681\n",
      "Epoch 88/150\n",
      "77/77 [==============================] - 0s 901us/step - loss: 0.6218 - accuracy: 0.6516\n",
      "Epoch 89/150\n",
      "77/77 [==============================] - 0s 909us/step - loss: 0.6127 - accuracy: 0.6667\n",
      "Epoch 90/150\n",
      "77/77 [==============================] - 0s 883us/step - loss: 0.6202 - accuracy: 0.6635\n",
      "Epoch 91/150\n",
      "77/77 [==============================] - 0s 853us/step - loss: 0.6185 - accuracy: 0.6633\n",
      "Epoch 92/150\n",
      "77/77 [==============================] - 0s 857us/step - loss: 0.6230 - accuracy: 0.6477\n",
      "Epoch 93/150\n",
      "77/77 [==============================] - 0s 849us/step - loss: 0.6279 - accuracy: 0.6494\n",
      "Epoch 94/150\n",
      "77/77 [==============================] - 0s 852us/step - loss: 0.6340 - accuracy: 0.6348\n",
      "Epoch 95/150\n",
      "77/77 [==============================] - 0s 826us/step - loss: 0.6227 - accuracy: 0.6509\n",
      "Epoch 96/150\n",
      "77/77 [==============================] - 0s 867us/step - loss: 0.6059 - accuracy: 0.6797\n",
      "Epoch 97/150\n",
      "77/77 [==============================] - 0s 876us/step - loss: 0.6156 - accuracy: 0.6643\n",
      "Epoch 98/150\n",
      "77/77 [==============================] - 0s 903us/step - loss: 0.6314 - accuracy: 0.6412\n",
      "Epoch 99/150\n",
      "77/77 [==============================] - 0s 886us/step - loss: 0.6216 - accuracy: 0.6589\n",
      "Epoch 100/150\n",
      "77/77 [==============================] - 0s 857us/step - loss: 0.6062 - accuracy: 0.6739\n",
      "Epoch 101/150\n",
      "77/77 [==============================] - 0s 878us/step - loss: 0.6112 - accuracy: 0.6699\n",
      "Epoch 102/150\n",
      "77/77 [==============================] - 0s 910us/step - loss: 0.6314 - accuracy: 0.6417\n",
      "Epoch 103/150\n",
      "77/77 [==============================] - 0s 882us/step - loss: 0.6209 - accuracy: 0.6587\n",
      "Epoch 104/150\n",
      "77/77 [==============================] - 0s 856us/step - loss: 0.6108 - accuracy: 0.6672\n",
      "Epoch 105/150\n",
      "77/77 [==============================] - 0s 838us/step - loss: 0.6170 - accuracy: 0.6461\n",
      "Epoch 106/150\n",
      "77/77 [==============================] - 0s 833us/step - loss: 0.6072 - accuracy: 0.6721\n",
      "Epoch 107/150\n",
      "77/77 [==============================] - 0s 837us/step - loss: 0.6142 - accuracy: 0.6597\n",
      "Epoch 108/150\n",
      "77/77 [==============================] - 0s 843us/step - loss: 0.6276 - accuracy: 0.6430\n",
      "Epoch 109/150\n",
      "77/77 [==============================] - 0s 930us/step - loss: 0.6254 - accuracy: 0.6341\n",
      "Epoch 110/150\n",
      "77/77 [==============================] - 0s 858us/step - loss: 0.6240 - accuracy: 0.6449\n",
      "Epoch 111/150\n",
      "77/77 [==============================] - 0s 808us/step - loss: 0.6259 - accuracy: 0.6447\n",
      "Epoch 112/150\n",
      "77/77 [==============================] - 0s 836us/step - loss: 0.6114 - accuracy: 0.6658\n",
      "Epoch 113/150\n",
      "77/77 [==============================] - 0s 888us/step - loss: 0.6081 - accuracy: 0.6591\n",
      "Epoch 114/150\n",
      "77/77 [==============================] - 0s 806us/step - loss: 0.6129 - accuracy: 0.6602\n",
      "Epoch 115/150\n",
      "77/77 [==============================] - 0s 853us/step - loss: 0.6147 - accuracy: 0.6570\n",
      "Epoch 116/150\n",
      "77/77 [==============================] - 0s 846us/step - loss: 0.6177 - accuracy: 0.6582\n",
      "Epoch 117/150\n",
      "77/77 [==============================] - 0s 858us/step - loss: 0.6204 - accuracy: 0.6408\n",
      "Epoch 118/150\n",
      "77/77 [==============================] - 0s 852us/step - loss: 0.6307 - accuracy: 0.6391\n",
      "Epoch 119/150\n",
      "77/77 [==============================] - 0s 865us/step - loss: 0.6346 - accuracy: 0.6269\n",
      "Epoch 120/150\n",
      "77/77 [==============================] - 0s 944us/step - loss: 0.6034 - accuracy: 0.6732\n",
      "Epoch 121/150\n",
      "77/77 [==============================] - 0s 863us/step - loss: 0.6102 - accuracy: 0.6600\n",
      "Epoch 122/150\n",
      "77/77 [==============================] - 0s 901us/step - loss: 0.6178 - accuracy: 0.6524\n",
      "Epoch 123/150\n",
      "77/77 [==============================] - 0s 871us/step - loss: 0.5999 - accuracy: 0.6848\n",
      "Epoch 124/150\n",
      "77/77 [==============================] - 0s 906us/step - loss: 0.6059 - accuracy: 0.6673\n",
      "Epoch 125/150\n",
      "77/77 [==============================] - 0s 871us/step - loss: 0.6144 - accuracy: 0.6566\n",
      "Epoch 126/150\n",
      "77/77 [==============================] - 0s 862us/step - loss: 0.6011 - accuracy: 0.6779\n",
      "Epoch 127/150\n",
      "77/77 [==============================] - 0s 833us/step - loss: 0.6166 - accuracy: 0.6384\n",
      "Epoch 128/150\n",
      "77/77 [==============================] - 0s 835us/step - loss: 0.6330 - accuracy: 0.6259\n",
      "Epoch 129/150\n",
      "77/77 [==============================] - 0s 853us/step - loss: 0.6188 - accuracy: 0.6401\n",
      "Epoch 130/150\n",
      "77/77 [==============================] - 0s 909us/step - loss: 0.6217 - accuracy: 0.6520\n",
      "Epoch 131/150\n",
      "77/77 [==============================] - 0s 827us/step - loss: 0.6087 - accuracy: 0.6615\n",
      "Epoch 132/150\n",
      "77/77 [==============================] - 0s 852us/step - loss: 0.5987 - accuracy: 0.6776\n",
      "Epoch 133/150\n",
      "77/77 [==============================] - 0s 836us/step - loss: 0.6200 - accuracy: 0.6372\n",
      "Epoch 134/150\n",
      "77/77 [==============================] - 0s 838us/step - loss: 0.6117 - accuracy: 0.6417\n",
      "Epoch 135/150\n",
      "77/77 [==============================] - 0s 858us/step - loss: 0.6131 - accuracy: 0.6563\n",
      "Epoch 136/150\n",
      "77/77 [==============================] - 0s 889us/step - loss: 0.6213 - accuracy: 0.6278\n",
      "Epoch 137/150\n",
      "77/77 [==============================] - 0s 826us/step - loss: 0.6155 - accuracy: 0.6534\n",
      "Epoch 138/150\n",
      "77/77 [==============================] - 0s 858us/step - loss: 0.6058 - accuracy: 0.6606\n",
      "Epoch 139/150\n",
      "77/77 [==============================] - 0s 846us/step - loss: 0.6181 - accuracy: 0.6533\n",
      "Epoch 140/150\n",
      "77/77 [==============================] - 0s 866us/step - loss: 0.6221 - accuracy: 0.6391\n",
      "Epoch 141/150\n",
      "77/77 [==============================] - 0s 842us/step - loss: 0.6089 - accuracy: 0.6503\n",
      "Epoch 142/150\n",
      "77/77 [==============================] - 0s 857us/step - loss: 0.6294 - accuracy: 0.6299\n",
      "Epoch 143/150\n",
      "77/77 [==============================] - 0s 854us/step - loss: 0.6205 - accuracy: 0.6336\n",
      "Epoch 144/150\n",
      "77/77 [==============================] - 0s 868us/step - loss: 0.6120 - accuracy: 0.6554\n",
      "Epoch 145/150\n",
      "77/77 [==============================] - 0s 851us/step - loss: 0.5930 - accuracy: 0.6933\n",
      "Epoch 146/150\n",
      "77/77 [==============================] - 0s 872us/step - loss: 0.5822 - accuracy: 0.6985\n",
      "Epoch 147/150\n",
      "77/77 [==============================] - 0s 905us/step - loss: 0.6032 - accuracy: 0.6757\n",
      "Epoch 148/150\n",
      "77/77 [==============================] - 0s 852us/step - loss: 0.5991 - accuracy: 0.6713\n",
      "Epoch 149/150\n",
      "77/77 [==============================] - 0s 960us/step - loss: 0.5887 - accuracy: 0.6983\n",
      "Epoch 150/150\n",
      "77/77 [==============================] - 0s 909us/step - loss: 0.5963 - accuracy: 0.6855\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fbc08329400>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras import optimizers\n",
    "# compile the keras model\n",
    "#model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "sgd = optimizers.SGD(lr = 0.01)    # stochastic gradient descent optimizer\n",
    "model.compile(optimizer = sgd, loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "model.fit(X, y, epochs=150, batch_size=10,verbose = 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the keras model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 0s 702us/step - loss: 0.6075 - accuracy: 0.6615\n",
      "Testing accuracy: 66.15\n"
     ]
    }
   ],
   "source": [
    "\n",
    "_, accuracy = model.evaluate(X, y)\n",
    "print('Testing accuracy: %.2f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What's Next?\n",
    "- Implement the bigger and deeper models\n",
    "- Read training and testing samples from a diectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
